<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>경사 하강법 (Gradient Descent) | Ganni Devlog</title>
<meta name="keywords" content="비용 함수, 경사 하강법, 확률적 경사 하강법 (SGD)" />
<meta name="description" content="머신 러닝 그리고 딥러닝 모델 학습의 목표는 더 정확한 예측을 위해 최적의 가중치와 편향을 찾는 것입니다. 이를 위한 방법으로 주로 사용되는 경사 하강법에 대해 알아보겠습니다.
 비용 함수 (Cost Function) X 축은 입력값이고 Y 축은 목푯값입니다. 이때 X 를 입력하면 Y 를 예측하여 출력하는 모델을 만든다고 가정해봅시다. 머신 러닝에서 𝑊 는 가중치 벡터를 의미하고 𝑏 는 편향을 나타냅니다.
위 그림에서는 3가지 선들 중 파란색 선이 모든 데이터 세트를 정확하게 예측한 것으로 보입니다.">
<meta name="author" content="">
<link rel="canonical" href="https://koolganni.github.io/posts/machine-learning/gradient-descent/" />
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.b15591da31b4f827d6dc0b97cf931d21b01610305321ac220bf755cf6aade94e.css" integrity="sha256-sVWR2jG0&#43;CfW3AuXz5MdIbAWEDBTIawiC/dVz2qt6U4=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js" integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5&#43;kdJvBz5iKbt6B5PJI="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://koolganni.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://koolganni.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://koolganni.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://koolganni.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://koolganni.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.81.0" />
<meta property="og:title" content="경사 하강법 (Gradient Descent)" />
<meta property="og:description" content="머신 러닝 그리고 딥러닝 모델 학습의 목표는 더 정확한 예측을 위해 최적의 가중치와 편향을 찾는 것입니다. 이를 위한 방법으로 주로 사용되는 경사 하강법에 대해 알아보겠습니다.
 비용 함수 (Cost Function) X 축은 입력값이고 Y 축은 목푯값입니다. 이때 X 를 입력하면 Y 를 예측하여 출력하는 모델을 만든다고 가정해봅시다. 머신 러닝에서 𝑊 는 가중치 벡터를 의미하고 𝑏 는 편향을 나타냅니다.
위 그림에서는 3가지 선들 중 파란색 선이 모든 데이터 세트를 정확하게 예측한 것으로 보입니다." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://koolganni.github.io/posts/machine-learning/gradient-descent/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-04-11T19:22:21&#43;09:00" />
<meta property="article:modified_time" content="2021-04-11T19:22:21&#43;09:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="경사 하강법 (Gradient Descent)"/>
<meta name="twitter:description" content="머신 러닝 그리고 딥러닝 모델 학습의 목표는 더 정확한 예측을 위해 최적의 가중치와 편향을 찾는 것입니다. 이를 위한 방법으로 주로 사용되는 경사 하강법에 대해 알아보겠습니다.
 비용 함수 (Cost Function) X 축은 입력값이고 Y 축은 목푯값입니다. 이때 X 를 입력하면 Y 를 예측하여 출력하는 모델을 만든다고 가정해봅시다. 머신 러닝에서 𝑊 는 가중치 벡터를 의미하고 𝑏 는 편향을 나타냅니다.
위 그림에서는 3가지 선들 중 파란색 선이 모든 데이터 세트를 정확하게 예측한 것으로 보입니다."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://koolganni.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "경사 하강법 (Gradient Descent)",
      "item": "https://koolganni.github.io/posts/machine-learning/gradient-descent/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "경사 하강법 (Gradient Descent)",
  "name": "경사 하강법 (Gradient Descent)",
  "description": "머신 러닝 그리고 딥러닝 모델 학습의 목표는 더 정확한 예측을 위해 최적의 가중치와 편향을 찾는 것입니다. 이를 위한 방법으로 주로 사용되는 경사 하강법에 대해 알아보겠습니다.\n 비용 함수 (Cost Function) X 축은 입력값이고 Y 축은 목푯값입니다. 이때 X 를 입력하면 Y 를 예측하여 출력하는 모델을 만든다고 가정해봅시다. 머신 러닝에서 𝑊 는 가중치 벡터를 의미하고 𝑏 는 편향을 나타냅니다.\n위 그림에서는 3가지 선들 중 파란색 선이 모든 데이터 세트를 정확하게 예측한 것으로 보입니다.",
  "keywords": [
    "비용 함수", "경사 하강법", "확률적 경사 하강법 (SGD)"
  ],
  "articleBody": " 머신 러닝 그리고 딥러닝 모델 학습의 목표는 더 정확한 예측을 위해 최적의 가중치와 편향을 찾는 것입니다. 이를 위한 방법으로 주로 사용되는 경사 하강법에 대해 알아보겠습니다.\n 비용 함수 (Cost Function) X 축은 입력값이고 Y 축은 목푯값입니다. 이때 X 를 입력하면 Y 를 예측하여 출력하는 모델을 만든다고 가정해봅시다. 머신 러닝에서 𝑊 는 가중치 벡터를 의미하고 𝑏 는 편향을 나타냅니다.\n위 그림에서는 3가지 선들 중 파란색 선이 모든 데이터 세트를 정확하게 예측한 것으로 보입니다. 이러한 선을 우리는 어떻게 찾을 수 있을까요?\n모델의 예측이 얼마나 잘못되었는지를 나타내는 수 손실을 활용할 수 있습니다. 예를 들어 아래 그림의 왼쪽은 손실이 큰 모델이고 오른쪽은 손실이 작은 모델입니다.\n모델을 훈련시킬 때에는 하나의 예시가 아니라 전체 데이터 세트에서 손실을 최소화해야 합니다. 따라서 개별 손실을 종합할 수 있는 비용 함수 (손실 함수)를 사용합니다.\n비용 함수는 임의의 함수를 사용할 수도 있지만 일반적으로는 평균 제곱 오차(MSE)와 교차 엔트로피 오차(CEE)를 사용합니다. 이번 글에서는 평균 제곱 오차를 기준으로 살펴보겠습니다.\n평균 제곱 오차는 N개의 데이터의 평균 제곱 손실(L2 손실)입니다. 개별 제곱 손실을 모두 합한 다음 평균을 구합니다.\n위에서 살펴본 선형 회귀 모델의 MSE 비용 함수를 생각해보겠습니다. 아래와 같이 우리는 선형 회귀 모델의 가중치(𝑊), 편향(𝑏) 매개변수에 대한 비용 함수를 구해야 합니다.\n그럼 이러한 비용 함수, 즉 손실을 최소화하는 모델의 매개변수는 어떻게 찾을 수 있을까요? 전체 데이터 세트에 대해 모든 매개변수의 비용 함수를 계산하는 것은 매우 비효율적인 방법입니다. 따라서 머신 러닝에서는 더 나은 방법인 경사 하강법을 활용합니다.\n 경사 하강법 (Gradient Descent) 회귀 문제에서는 가중치(𝑊)에 대한 비용 함수를 그리면 아래와 같이 항상 볼록 함수 모양을 갖습니다.\n볼록 문제에서는 기울기가 정확하게 0인 지점인 최소값이 하나만 존재합니다. 이 최소값이 손실 함수가 수렴하는 값이며 동시에 우리가 찾고자 하는 손실을 최소화하는 지점입니다.\n경사 하강법은 가중치(𝑊) 값 변화에 따른 손실 함수값의 변화를 측정하기 위해 미분을 활용합니다. 미분을 통해 한 점에 대한 접선의 기울기를 알면 어느 방향으로 점을 움직여야 함수값이 감소 혹은 증가하는지 알 수 있기 때문입니다.\n위 그림에서 초록색 선은 𝑊 가 임의의 값을 가지게 되는 경우에 대해서 그래프 상으로 접선의 기울기를 보여줍니다. 주목할 것은 맨 아래의 볼록한 부분으로 갈수록 접선의 기울기가 점차 작아지다가 결국 cost 가 최소화되는 지점에서는 0 이 된다는 것입니다.\n즉, 경사 하강법의 아이디어는 비용 함수를 미분하여 현재 𝑊 에서의 접선의 기울기를 구하고 기울기가 낮은 방향으로 (0 인 곳을 향해) 𝑊 값을 변경하는 작업을 반복하는 것에 있습니다.\n𝑊 를 업데이트하는 식은 아래와 같습니다.\n현재 𝑊 에서의 접선의 기울기와 ⍺(Learning rate)를 곱한 값을 현재 𝑊 에서 빼서 새로운 𝑊 로 업데이트하는 것을 의미합니다.\n ⍺(Learning rate) : 𝑊 를 얼마나 크게 변경할지 결정합니다. ⍺ 가 지나치게 높다면 𝑊 값이 발산할 수 있고 반대로 지나치게 낮다면 학습 속도가 느려집니다.  이 식에 따라 접선의 기울기가 음수인 경우에는 𝑊 값이 증가하게 되는데 결과적으로 접선의 기울기가 0 인 방향으로 𝑊 값이 조정됩니다.\n반대로 접선의 기울기가 양수인 경우에는 𝑊 값이 감소하게 되고 이 또한 결과적으로 접선의 기울기가 0 인 방향으로 𝑊 값이 조정됩니다.\n이러한 과정을 통해 경사 하강법은 전체 데이터 세트에 대해 동시에 학습이 진행됩니다.\n 확률적 경사 하강법 (Stochastic Gradient Descent) 경사 하강법은 최적의 파라미터를 찾기 위한 좋은 도구이지만 사실 우리가 마주하는 문제는 선형 회귀 모델처럼 볼록 함수가 아닐 때가 많습니다. 특히 신경망의 경우 대부분 아래 그림과 같이 계란판처럼 생긴 비볼록 함수를 보여줍니다.\n비볼록 함수는 시작 위치에 따라 다른 지점을 찾기 때문에 단순한 경사 하강법으로는 전역 최솟값(Global Minimum)을 찾지 못하고 지역 최솟값(Local Minimum)에 빠질 위험이 있습니다.\n확률적 경사 하강법(Stochastic Gradient Descent)은 이러한 문제를 어느 정도 해결해줍니다. 전체 데이터를 가지고 파라미터를 업데이트하는 경사 하강법과 달리 확률적 경사 하강법은 확률적으로 미니 배치를 가지고 파라미터를 업데이트합니다.1\n따라서 비용 함수 그래프의 곡선 모양이 매번 바뀌게 되고 지역 최솟값 부분이 더 이상 기울기가 0 이 되지 않도록 하면서 해당 지점에서 탈출하도록 도와줍니다. 또한 데이터의 일부를 가지고 파라미터를 업데이트하기 때문에 연산 자원을 좀 더 효율적으로 활용합니다.\n이외에도 Momentum, AdaGrad, Adam, RMSprop 등 경사 하강법의 단점을 보완하기 위한 여러 방법들이 있습니다.\n (추가) 경사 하강법의 편미분 계산 과정  θ0(편향)과 θ1(가중치)에 대한 비용 함수 편미분을 통해 파라미터를 업데이트 하는 과정입니다.   References  https://developers.google.com/machine-learning/crash-course/descending-into-ml/ 모두를 위한 딥러닝 강좌 시즌 1 딥러닝을 이용한 자연어 처리 입문 https://www.boostcourse.org/ai222/lecture/24509 밑바닥부터 시작하는 딥러닝 1 - 한빛미디어 (2017)    미니 배치 확률적 경사 하강법에 대한 설명입니다. ↩︎\n   ",
  "wordCount" : "643",
  "inLanguage": "en",
  "datePublished": "2021-04-11T19:22:21+09:00",
  "dateModified": "2021-04-11T19:22:21+09:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://koolganni.github.io/posts/machine-learning/gradient-descent/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Ganni Devlog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://koolganni.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>
<noscript>
    <style type="text/css">
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: #1d1e20;
                --entry: #2e2e33;
                --primary: rgba(255, 255, 255, 0.84);
                --secondary: rgba(255, 255, 255, 0.56);
                --tertiary: rgba(255, 255, 255, 0.16);
                --content: rgba(255, 255, 255, 0.74);
                --hljs-bg: #2e2e33;
                --code-bg: #37383e;
                --border: #333;
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://koolganni.github.io/" accesskey="h" title="Ganni Devlog (Alt + H)">Ganni Devlog</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu" onscroll="menu_on_scroll()">
            <li>
                <a href="https://koolganni.github.io/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="https://koolganni.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      경사 하강법 (Gradient Descent)
    </h1>
    <div class="post-meta">April 11, 2021
</div>
  </header> 
  <div class="post-content"><blockquote>
<p>머신 러닝 그리고 딥러닝 모델 학습의 목표는 더 정확한 예측을 위해 최적의 가중치와 편향을 찾는 것입니다. 이를 위한 방법으로 주로 사용되는 <code>경사 하강법</code>에 대해 알아보겠습니다.</p>
</blockquote>
<h3 id="비용-함수-cost-function">비용 함수 (Cost Function)<a hidden class="anchor" aria-hidden="true" href="#비용-함수-cost-function">#</a></h3>
<p>X 축은 입력값이고 Y 축은 목푯값입니다. 이때 X 를 입력하면 Y 를 예측하여 출력하는 모델을 만든다고 가정해봅시다. 머신 러닝에서 𝑊 는 가중치 벡터를 의미하고 𝑏 는 편향을 나타냅니다.</p>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/76609403/118235928-5cea7a80-b4d0-11eb-9ef9-96721f3fcc38.png" alt="image"  />
</p>
<p>위 그림에서는 3가지 선들 중 파란색 선이 모든 데이터 세트를 정확하게 예측한 것으로 보입니다. 이러한 선을 우리는 어떻게 찾을 수 있을까요?</p>
<p>모델의 예측이 얼마나 잘못되었는지를 나타내는 수 <code>손실</code>을 활용할 수 있습니다. 예를 들어 아래 그림의 왼쪽은 손실이 큰 모델이고 오른쪽은 손실이 작은 모델입니다.</p>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/76609403/118237422-480ee680-b4d2-11eb-897b-abd89e4f8a3c.png" alt="image"  />
</p>
<p>모델을 훈련시킬 때에는 하나의 예시가 아니라 전체 데이터 세트에서 <strong>손실을 최소화</strong>해야 합니다. 따라서 개별 손실을 종합할 수 있는 <code>비용 함수 (손실 함수)</code>를 사용합니다.</p>
<p><code>비용 함수</code>는 임의의 함수를 사용할 수도 있지만 일반적으로는 평균 제곱 오차(MSE)와 교차 엔트로피 오차(CEE)를 사용합니다. 이번 글에서는 평균 제곱 오차를 기준으로 살펴보겠습니다.</p>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/76609403/118238116-0f234180-b4d3-11eb-9dea-1764a6f8cf90.png" alt="image"  />
</p>
<p><code>평균 제곱 오차</code>는 N개의 데이터의 평균 제곱 손실(L2 손실)입니다. 개별 제곱 손실을 모두 합한 다음 평균을 구합니다.</p>
<p>위에서 살펴본 선형 회귀 모델의 MSE 비용 함수를 생각해보겠습니다. 아래와 같이 우리는 선형 회귀 모델의 가중치(𝑊), 편향(𝑏) 매개변수에 대한 비용 함수를 구해야 합니다.</p>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/76609403/118239684-10556e00-b4d5-11eb-80f8-268ece36e9ba.png" alt="image"  />
</p>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/76609403/118239842-3d098580-b4d5-11eb-863a-282c12c05810.png" alt="image"  />
</p>
<p>그럼 이러한 비용 함수, 즉 <strong>손실을 최소화하는 모델의 매개변수</strong>는 어떻게 찾을 수 있을까요? 전체 데이터 세트에 대해 모든 매개변수의 비용 함수를 계산하는 것은 매우 비효율적인 방법입니다. 따라서 머신 러닝에서는 더 나은 방법인 <code>경사 하강법</code>을 활용합니다.</p>
<hr>
<h3 id="경사-하강법-gradient-descent">경사 하강법 (Gradient Descent)<a hidden class="anchor" aria-hidden="true" href="#경사-하강법-gradient-descent">#</a></h3>
<p>회귀 문제에서는 가중치(𝑊)에 대한 비용 함수를 그리면 아래와 같이 항상 볼록 함수 모양을 갖습니다.</p>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/76609403/118246112-890bf880-b4dc-11eb-9ee6-d0ec484ee05d.png" alt="image"  />
</p>
<p>볼록 문제에서는 기울기가 정확하게 0인 지점인 최소값이 하나만 존재합니다. 이 최소값이 손실 함수가 수렴하는 값이며 동시에 우리가 찾고자 하는 손실을 최소화하는 지점입니다.</p>
<p><code>경사 하강법</code>은 가중치(𝑊) 값 변화에 따른 손실 함수값의 변화를 측정하기 위해 <strong>미분</strong>을 활용합니다. 미분을 통해 한 점에 대한 <strong>접선의 기울기</strong>를 알면 어느 방향으로 점을 움직여야 함수값이 감소 혹은 증가하는지 알 수 있기 때문입니다.</p>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/76609403/118258352-b3fd4900-b4ea-11eb-8c61-a818787a995c.png" alt="image"  />
</p>
<p>위 그림에서 초록색 선은 𝑊 가 임의의 값을 가지게 되는 경우에 대해서 그래프 상으로 접선의 기울기를 보여줍니다. 주목할 것은 맨 아래의 볼록한 부분으로 갈수록 접선의 기울기가 점차 작아지다가 결국 cost 가 최소화되는 지점에서는 0 이 된다는 것입니다.</p>
<p>즉, <code>경사 하강법</code>의 아이디어는 비용 함수를 미분하여 현재 𝑊 에서의 접선의 기울기를 구하고 <strong>기울기가 낮은 방향</strong>으로 (0 인 곳을 향해) 𝑊 값을 변경하는 작업을 반복하는 것에 있습니다.</p>
<p>𝑊 를 업데이트하는 식은 아래와 같습니다.</p>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/76609403/118257601-c925a800-b4e9-11eb-8266-eed9e41e4d37.png" alt="image"  />
</p>
<p>현재 𝑊 에서의 접선의 기울기와 ⍺(Learning rate)를 곱한 값을 현재 𝑊 에서 <strong>빼서</strong> 새로운 𝑊 로 업데이트하는 것을 의미합니다.</p>
<ul>
<li>⍺(Learning rate) : 𝑊 를 얼마나 크게 변경할지 결정합니다. ⍺ 가 지나치게 높다면 𝑊 값이 발산할 수 있고 반대로 지나치게 낮다면 학습 속도가 느려집니다.</li>
</ul>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/76609403/118258464-d8f1bc00-b4ea-11eb-929a-19548e141bb8.png" alt="image"  />
</p>
<p>이 식에 따라 접선의 기울기가 음수인 경우에는 𝑊 값이 증가하게 되는데 결과적으로 접선의 기울기가 0 인 방향으로 𝑊 값이 조정됩니다.</p>
<p>반대로 접선의 기울기가 양수인 경우에는 𝑊 값이 감소하게 되고 이 또한 결과적으로 접선의 기울기가 0 인 방향으로 𝑊 값이 조정됩니다.</p>
<p>이러한 과정을 통해 경사 하강법은 전체 데이터 세트에 대해 동시에 학습이 진행됩니다.</p>
<hr>
<h3 id="확률적-경사-하강법-stochastic-gradient-descent">확률적 경사 하강법 (Stochastic Gradient Descent)<a hidden class="anchor" aria-hidden="true" href="#확률적-경사-하강법-stochastic-gradient-descent">#</a></h3>
<p>경사 하강법은 최적의 파라미터를 찾기 위한 좋은 도구이지만 사실 우리가 마주하는 문제는 선형 회귀 모델처럼 볼록 함수가 아닐 때가 많습니다. 특히 신경망의 경우 대부분 아래 그림과 같이 계란판처럼 생긴 <strong>비볼록 함수</strong>를 보여줍니다.</p>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/76609403/118261000-f5dbbe80-b4ed-11eb-89f8-0c6b3d8ecb0d.png" alt="image"  />
</p>
<p>비볼록 함수는 시작 위치에 따라 다른 지점을 찾기 때문에 단순한 경사 하강법으로는 <code>전역 최솟값(Global Minimum)</code>을 찾지 못하고 <code>지역 최솟값(Local Minimum)</code>에 빠질 위험이 있습니다.</p>
<p><code>확률적 경사 하강법(Stochastic Gradient Descent)</code>은 이러한 문제를 어느 정도 해결해줍니다. 전체 데이터를 가지고 파라미터를 업데이트하는 경사 하강법과 달리 확률적 경사 하강법은 <strong>확률적으로 미니 배치</strong>를 가지고 파라미터를 업데이트합니다.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/76609403/118271813-bcf71600-b4fc-11eb-9f34-5a630376a646.png" alt="image"  />
</p>
<p>따라서 비용 함수 그래프의 곡선 모양이 매번 바뀌게 되고 지역 최솟값 부분이 더 이상 기울기가 0 이 되지 않도록 하면서 해당 지점에서 탈출하도록 도와줍니다. 또한 데이터의 일부를 가지고 파라미터를 업데이트하기 때문에 연산 자원을 좀 더 효율적으로 활용합니다.</p>
<p>이외에도 Momentum, AdaGrad, Adam, RMSprop 등 경사 하강법의 단점을 보완하기 위한 여러 방법들이 있습니다.</p>
<hr>
<h3 id="추가-경사-하강법의-편미분-계산-과정">(추가) 경사 하강법의 편미분 계산 과정<a hidden class="anchor" aria-hidden="true" href="#추가-경사-하강법의-편미분-계산-과정">#</a></h3>
<ul>
<li>θ0(편향)과 θ1(가중치)에 대한 비용 함수 편미분을 통해 파라미터를 업데이트 하는 과정입니다.</li>
</ul>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/76609403/118262739-4b18cf80-b4f0-11eb-8b6f-f9b561b45afa.png" alt="image"  />
</p>
<p><img loading="lazy" src="https://user-images.githubusercontent.com/76609403/118262763-553ace00-b4f0-11eb-8c1e-33e8ebe233b6.png" alt="image"  />
</p>
<hr>
<h3 id="references">References<a hidden class="anchor" aria-hidden="true" href="#references">#</a></h3>
<ul>
<li><a href="https://developers.google.com/machine-learning/crash-course/descending-into-ml/">https://developers.google.com/machine-learning/crash-course/descending-into-ml/</a></li>
<li><a href="https://youtu.be/TxIVr-nk1so">모두를 위한 딥러닝 강좌 시즌 1</a></li>
<li><a href="https://wikidocs.net/21670">딥러닝을 이용한 자연어 처리 입문</a></li>
<li><a href="https://www.boostcourse.org/ai222/lecture/24509">https://www.boostcourse.org/ai222/lecture/24509</a></li>
<li>밑바닥부터 시작하는 딥러닝 1 - 한빛미디어 (2017)</li>
</ul>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>미니 배치 확률적 경사 하강법에 대한 설명입니다. <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>

</div>
  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://koolganni.github.io/tags/%EB%B9%84%EC%9A%A9-%ED%95%A8%EC%88%98/">비용 함수</a></li>
      <li><a href="https://koolganni.github.io/tags/%EA%B2%BD%EC%82%AC-%ED%95%98%EA%B0%95%EB%B2%95/">경사 하강법</a></li>
      <li><a href="https://koolganni.github.io/tags/%ED%99%95%EB%A5%A0%EC%A0%81-%EA%B2%BD%EC%82%AC-%ED%95%98%EA%B0%95%EB%B2%95-sgd/">확률적 경사 하강법 (SGD)</a></li>
    </ul>
  </footer>
</article>
    </main>
    <footer class="footer">
    <span>&copy; 2021 <a href="https://koolganni.github.io/">Ganni Devlog</a></span>
    <span>&middot;</span>
    <span>Powered by <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a></span>
    <span>&middot;</span>
    <span>Theme <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a></span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)">
    <button class="top-link" id="top-link" type="button" accesskey="g">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z" />
        </svg>
    </button>
</a>

<script>
    window.onload = function () {
        if (localStorage.getItem("menu-scroll-position")) {
            document.getElementById('menu').scrollLeft = localStorage.getItem("menu-scroll-position");
        }
    }

    function menu_on_scroll() {
        localStorage.setItem("menu-scroll-position", document.getElementById('menu').scrollLeft);
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        container.appendChild(copybutton);
    });
</script>
</body>

</html>
