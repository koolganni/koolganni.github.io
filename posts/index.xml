<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Ganni Devlog</title>
    <link>https://koolganni.github.io/posts/</link>
    <description>Recent content in Posts on Ganni Devlog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>kr-ko</language>
    <lastBuildDate>Fri, 07 May 2021 23:09:52 +0900</lastBuildDate><atom:link href="https://koolganni.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[추천 시스템] 추천 시스템의 성능 평가</title>
      <link>https://koolganni.github.io/posts/rec-sys/evaluation-metric/</link>
      <pubDate>Fri, 07 May 2021 23:09:52 +0900</pubDate>
      
      <guid>https://koolganni.github.io/posts/rec-sys/evaluation-metric/</guid>
      <description>추천 시스템의 성능은 어떻게 평가할까요? 어떤 추천 시스템인지에 따라 방법은 다양할 것입니다. 이번 글에서는 대표적인 정량적 평가 지표 MAP, NDCG, RMSE 에 대해 알아보겠습니다.
 좋은 추천 시스템이란 추천 시스템의 성능, 다시 말해 사용자에게 얼마나 적절한 아이템을 추천했는지를 우리는 어떻게 평가할 수 있을까요? 서비스 관점에서는 추천 시스템을 적용하기 전과 후의 제품 매출이나 구독 등 실제 수익이 얼마나 향상되었는지를 확인해 볼 수 있을 것입니다. 혹은 A/B Test 와 같은 대조실험을 통해 어떤 추천 방법이 더 나은 고객 반응을 이끌었는지 비교해 볼 수 있을 것입니다.</description>
    </item>
    
    <item>
      <title>신뢰구간 (Confidence Interval)</title>
      <link>https://koolganni.github.io/posts/statistics/confidence-interval/</link>
      <pubDate>Sat, 01 May 2021 22:51:04 +0900</pubDate>
      
      <guid>https://koolganni.github.io/posts/statistics/confidence-interval/</guid>
      <description>가설 검정을 하다보면 95%의 신뢰구간, 99%의 신뢰구간을 이야기할 때가 많습니다. 여기서 신뢰구간이란 정확히 무엇을 의미하는 것일까요?
 신뢰구간과 신뢰도의 의미 먼저, 표본의 정보를 활용해 모집단의 특징을 추측하는 것을 우리는 &amp;lsquo;추정&amp;rsquo;이라고 합니다.
모집단의 특징 중에서 모집단의 평균, 즉 모평균(μ)을 추정하는 상황을 가정해봅시다.
예를 들어 모집단의 평균 나이가 30일 때 모평균이 1 ≤ μ ≤ 100 추정범위 안에 들어가는지 추측하는 것은 100% 확실한 추정입니다. 하지만 모평균으로 추정될 수 있는 값이 매우 많기 때문에 추정의 가치가 없다고 할 수 있습니다.</description>
    </item>
    
    <item>
      <title>경사 하강법 (Gradient Descent)</title>
      <link>https://koolganni.github.io/posts/machine-learning/gradient-descent/</link>
      <pubDate>Sun, 11 Apr 2021 19:22:21 +0900</pubDate>
      
      <guid>https://koolganni.github.io/posts/machine-learning/gradient-descent/</guid>
      <description>머신 러닝 그리고 딥러닝 모델 학습의 목표는 더 정확한 예측을 위해 최적의 가중치와 편향을 찾는 것입니다. 이를 위한 방법으로 주로 사용되는 경사 하강법에 대해 알아보겠습니다.
 비용 함수 (Cost Function) X 축은 입력값이고 Y 축은 목푯값입니다. 이때 X 를 입력하면 Y 를 예측하여 출력하는 모델을 만든다고 가정해봅시다. 머신 러닝에서 𝑊 는 가중치 벡터를 의미하고 𝑏 는 편향을 나타냅니다.
위 그림에서는 3가지 선들 중 파란색 선이 모든 데이터 세트를 정확하게 예측한 것으로 보입니다.</description>
    </item>
    
    <item>
      <title>로지스틱 회귀 (Logistic Regression)</title>
      <link>https://koolganni.github.io/posts/machine-learning/logistic-regression/</link>
      <pubDate>Sat, 13 Feb 2021 19:44:41 +0900</pubDate>
      
      <guid>https://koolganni.github.io/posts/machine-learning/logistic-regression/</guid>
      <description>이진 분류 (Binary Classification) 문제에서 좋은 성능을 보이며 동시에 딥러닝에서 중요한 개념을 포함하고 있는 로지스틱 회귀(분류)에 대해 알아보겠습니다.
 Binary Classification 스팸 메일과 스팸이 아닌 메일, 긍정 리뷰와 부정 리뷰, 악성 종양과 양성 종양 등 두 가지 선택지 중에서 하나를 예측하는 것을 우리는 이진 분류(Binary Classification)라고 합니다.
이진 분류 문제를 해결하기 위해서는 어떤 모델을 사용해야 할까요? 아래와 같이 종양의 크기에 따라 악성(1)인지 양성(0)인지 분류하는 선형 회귀 모델을 만든다고 가정해봅시다.</description>
    </item>
    
    <item>
      <title>L1 과 L2 정규화 (Regularization)</title>
      <link>https://koolganni.github.io/posts/machine-learning/l1-l2-regularization/</link>
      <pubDate>Sat, 06 Feb 2021 20:21:54 +0900</pubDate>
      
      <guid>https://koolganni.github.io/posts/machine-learning/l1-l2-regularization/</guid>
      <description>모델의 성능을 높이는 데에는 여러 방법이 있습니다. Overfitting(과대적합)을 억제하는 방법 중 L1 정규화 및 L2 정규화 기술에 대해 알아보겠습니다.
 Overfitting 아래 그림의 맨 오른쪽은 모델이 주어진 데이터 세트에 대해 지나치게 많이 학습을 한 Overfitting(과대적합)의 모습을 보여줍니다. 이는 모델이 학습 데이터를 과하게 암기하여 훈련 데이터에 포함된 노이즈까지 학습한 상태라고 해석할 수 있습니다.
학습 데이터에 모델이 Overfitting 되는 현상은 모델의 성능을 떨어트리는 주요 이슈입니다. 훈련 데이터에 대한 정확도는 높을지라도 새로운 데이터, 즉 검증 데이터나 테스트 데이터에 대해서는 제대로 동작하지 않습니다.</description>
    </item>
    
  </channel>
</rss>
