<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ganni Devlog</title>
    <link>https://koolganni.github.io/</link>
    <description>Recent content on Ganni Devlog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>kr-ko</language>
    <lastBuildDate>Fri, 07 May 2021 23:09:52 +0900</lastBuildDate><atom:link href="https://koolganni.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[추천 시스템] 추천 시스템의 성능 평가</title>
      <link>https://koolganni.github.io/posts/rec-sys/evaluation-metric/</link>
      <pubDate>Fri, 07 May 2021 23:09:52 +0900</pubDate>
      
      <guid>https://koolganni.github.io/posts/rec-sys/evaluation-metric/</guid>
      <description>추천 시스템의 성능은 어떻게 평가할까요? 어떤 추천 시스템인지에 따라 방법은 다양할 것입니다. 이번 글에서는 대표적인 정량적 평가 지표 MAP, NDCG, RMSE 에 대해 알아보겠습니다.
 좋은 추천 시스템이란 추천 시스템의 성능, 다시 말해 사용자에게 얼마나 적절한 아이템을 추천했는지를 우리는 어떻게 평가할 수 있을까요? 서비스 관점에서는 추천 시스템을 적용하기 전과 후의 제품 매출이나 구독 등 실제 수익이 얼마나 향상되었는지를 확인해 볼 수 있을 것입니다. 혹은 A/B Test 와 같은 대조실험을 통해 어떤 추천 방법이 더 나은 고객 반응을 이끌었는지 비교해 볼 수 있을 것입니다.</description>
    </item>
    
    <item>
      <title>신뢰구간 (Confidence Interval)</title>
      <link>https://koolganni.github.io/posts/statistics/confidence-interval/</link>
      <pubDate>Sat, 01 May 2021 22:51:04 +0900</pubDate>
      
      <guid>https://koolganni.github.io/posts/statistics/confidence-interval/</guid>
      <description>가설 검정을 하다보면 95%의 신뢰구간, 99%의 신뢰구간을 이야기할 때가 많습니다. 여기서 신뢰구간이란 정확히 무엇을 의미하는 것일까요?
 신뢰구간과 신뢰도의 의미 먼저, 표본의 정보를 활용해 모집단의 특징을 추측하는 것을 우리는 &amp;lsquo;추정&amp;rsquo;이라고 합니다.
모집단의 특징 중에서 모집단의 평균, 즉 모평균(μ)을 추정하는 상황을 가정해봅시다.
예를 들어 모집단의 평균 나이가 30일 때 모평균이 1 ≤ μ ≤ 100 추정범위 안에 들어가는지 추측하는 것은 100% 확실한 추정입니다. 하지만 모평균으로 추정될 수 있는 값이 매우 많기 때문에 추정의 가치가 없다고 할 수 있습니다.</description>
    </item>
    
    <item>
      <title>경사 하강법 (Gradient Descent)</title>
      <link>https://koolganni.github.io/posts/machine-learning/gradient-descent/</link>
      <pubDate>Sun, 11 Apr 2021 19:22:21 +0900</pubDate>
      
      <guid>https://koolganni.github.io/posts/machine-learning/gradient-descent/</guid>
      <description>머신러닝 그리고 딥러닝 모델 학습에서 가장 중요한 것은 실제 값과 예측 값의 차이를 최소화해 더 정확한 예측을 하는 것입니다. 경사 하강법은 이를 위한 방법으로 &amp;lsquo;데이터를 기반으로 알고리즘이 스스로 학습한다&amp;rsquo;는 머신러닝의 개념을 실현한 핵심 기법 중 하나입니다.
 비용 함수 (Cost Function) 아래 그림과 같이 주어진 X 에 대해 Y 를 예측하는 예측 함수, 다시 말해 가설 함수 Y = B0 + B1*X를 구하는 상황을 생각해봅시다. 우리는 실제 관측치인 주황색 점과 가설 함수의 예측치 간의 차이(error)를 최소화하는 B0(절편)과 B1(기울기)를 알아야 합니다.</description>
    </item>
    
    
    
  </channel>
</rss>
