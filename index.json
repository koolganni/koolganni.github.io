[{"content":" A/B 테스트와 같은 제품 실험을 자주 실행하는 조직일수록, 실험 분석 결과에 따라 다음 액션이 빠르게 결정됩니다. 실험 분석에서 가장 중요한 것은 무엇일까요? Microsoft Research 에서는 신뢰할 수 있는 실험 분석을 위해서는 데이터 퀄리티가 기본적으로 갖춰줘야 한다고 이야기합니다.\n  이 글은 Microsoft Experimentation Platform 팀에서 소개하는 \u0026ldquo;Data Quality: Fundamental Building Blocks for Trustworthy A/B testing Analysis\u0026rdquo; 를 바탕으로 작성되었습니다.\n Introduction 데이터는 기술 산업의 모든 제품 라이프사이클에서 중요한 역할을 합니다. 데이터를 통해 우리는 제품을 개선하고 더 나은 사용자 경험을 제공할 수 있는 인사이트를 얻을 수 있습니다. 하지만 이러한 인사이트는 신뢰할 수 있는 데이터에서 도출되어야만 실행이 가능합니다. 예를 들어 내비게이션 앱의 경우 정확한 위치 탐지 데이터에 의존해 사용자에게 방향을 제시합니다.\n데이터 퀄리티는 A/B 테스트에서 특히 중요한데요, A/B 테스트를 통해 다양한 관점에서 새로운 feature 를 평가하고 데이터에 기반한 결정을 내릴 수 있습니다. 그러나 신뢰할 수 없는 데이터는 사용자 경험이나 주요 지표를 악화시키는, 잘못된 분석과 의사결정으로 이어질 수 있습니다.\n이번 글에서는 신뢰할 수 있는 A/B 테스트 분석을 위해 데이터 퀄리티를 확인할 수 있는 도구와 방법론을 아래와 같은 순서로 살펴보겠습니다.\n1. 데이터 퀄리티는 A/B 테스트에 어떤 영향을 끼칠까? 2. 데이터 퀄리티를 위해 가장 중요한 체크리스트는? 3. 데이터 퀄리티를 꾸준히 모니터링할 수 있는 방법은?  데이터 퀄리티는 A/B 테스트에 어떤 영향을 끼칠까? A/B 테스트 결과는 완전하고 정확한 데이터를 기반으로 하는 경우에만 신뢰할 수 있고 실행 가능합니다. 하지만 어떻게 우리가 사용하고 있는 데이터를 신뢰할 수 있다고 판단할 수 있을까요? 다음은 A/B 테스트에서 주의해야 할 몇 가지 데이터 퀄리티 이슈에 대한 징후입니다.\nSample Ratio Mismatch (SRM, 샘플 비율 불일치) SRM 은 실험군과 대조군에 할당된 트래픽이 구성했던 방식과 다른 경우로, Selection bias (선택 편향)으로 이어질 수 있습니다. 일반적으로 SRM 이 발생한 분석은 신뢰할 수 없는 것으로 보기 때문에 어떠한 결정을 내리는 데 사용해서는 안됩니다. 데이터 퀄리티 이슈로 인해 SRM 이 발생할 수 있는 시나리오는 여러가지가 있습니다. 예를 들어 원격에서 실험군/대조군 할당 정보의 불완전한 기록이나 불균형한 손실 등이 있겠습니다.\nSTEDI of metrics A/B 테스트에서 측정하는 지표는 Treatment effect (처치 효과)를 이해하고 관찰된 지표 변화를 해석하는 데 도움이 되도록 Sensitive(민감), Trustworthy(신뢰), Efficient(효율), Debuggable(디버깅 가능), Interpretable(해석 가능) 해야 합니다. 낮은 데이터 퀄리티는 특히 지표의 Sensitivity(민감도)와 Trustworthiness(신뢰도)에 부정적인 영향을 미칠 수 있습니다.\nSensitivity (민감도) 데이터 필드의 결측률이 매우 높으면 이 데이터 필드를 기반으로 하는 조건부 계산 메트릭은 샘플 크기가 매우 작습니다. 이러한 지표에 대한 가설 검정은 검정력이 부족할 것입니다.\n이상치는 민감도에 부정적인 영향을 미칠 수 있는 또 다른 흔한 문제입니다. 이상치는 분산을 증가시키고 지표를 변화시키는 큰 노이즈를 만들 수도 있습니다.\nTrustworthiness (신뢰도) 결측 데이터를 활용하는 지표는 잘못된 통계량과 신뢰할 수 없는 가설 검정 결과를 가져올 수 있습니다. 실험군과 대조군 사이에 누락된 데이터 비율이 불균형할 때에는 상황이 더 심각한데요, 리텐션 분석에서 데이터 누락은 실제 사용자가 이탈을 하지 않았음에도 불구하고 리텐션 지표를 낮출 수도 있습니다.\n다양한 세그먼트에 대한 심층 분석이 필요한 상황 혹은 세그먼트에 사용되는 필드가 부정확하거나 결측률이 높을 경우 이러한 세그먼트에 기반한 결과도 오해의 소지가 있을 수 있습니다.\n분석 결과 전달 지연 → 의사 결정 지연 통계 분석은 완전한 데이터에 의존합니다. 소프트웨어 제품에서는 일반적으로 데이터 생성과, 분석을 위한 데이터 준비 사이의 지연이 발생합니다. 예를 들어 가설 검증을 위해 여러 데이터 소스가 필요한 경우 모든 데이터를 사용 가능할 때까지 기다리는 시간은 상당히 길 수 있습니다. 분석이 늦어지면 의사결정 또한 늦어질 수 있습니다. 결과적으로 제품 경험에서 예상치 못한 regression 을 바로 감지하거나 고칠 수가 없습니다. 이러한 상황을 방지하려면 Service Level Agreements 를 충족하는, 잘 설계된 데이터 파이프라인이 매우 중요합니다.\n 데이터 퀄리티를 위해 가장 중요한 체크리스트는? 일반적인 데이터 퀄리티에는 Completeness(완전성), Uniqueness(고유성), Timeliness(적시성), Validity(유효성), Integrity(무결성), Consistency(일관성), Relevance(관련성), Compliance(규정 준수) 및 Retention(보존)이 포함됩니다.\nA/B 테스트 시나리오에 따라 데이터 퀄리티가 달라지는 사례를 많이 볼 수 있습니다. 잘못된 값을 증가시키는 새 feature 의 버그 같은 사례의 경우 A/B 테스트 과정에서 데이터 퀄리티를 측정하는 지표가 필요함을 알려줍니다.\n다음 체크리스트를 사용해 분석에서 데이터 퀄리티를 측정하기 위한 추가 메트릭을 설정할 수 있습니다.\n1. Missing rates (결측률) 각 컬럼에서 누락된 값은 얼마나 있는지? dummy value 로 결측치를 나타내는 특정 패턴이 있는지?  2. Invalid values (부적절한 값) 값이 적절한 형식을 따르고 있는지? 해당 컬럼에 맞는 값인지?  3. Join rates (조인 선택도) 다른 데이터 소스에서 데이터를 가져와 합칠 경우 join rate 이 충분히 높은지?  4. Uniqueness (고유성) 중복 항목이 있는지? 동일한 signal 에 대한 열이 두 개 이상 있는지?  5. Data delays (데이터 지연) 계산 시 사용할 수 있는 데이터의 비율이 어떻게 되는지? 이벤트가 기록된 시점과 데이터를 분석에 사용할 수 있는 시점 사이에 시간이 얼마나 걸리는지?  이외에도 데이터 보존 기간 및 개인 정보 보호 요구 사항을 포함한 데이터 정책을 준수하고 있는지 확인해야 합니다.\n그럼 A/B 테스트 결과를 분석하기 전에 주의해야 할 몇 가지 데이터 필드를 살펴보겠습니다.\nRandomization unit Randomization unit 은 우리가 실험군과 대조군을 임의로 할당하는 unit 을 의미합니다. 일반적인 radomization unit 은 사용자, 세션, 페이지, impression, 디바이스, 쿠키, 문서 등이 포함됩니다. 데이터 퀄리티 검사는 동일한 radomization unit 에 속한 데이터가 정확하고 준수된 방식으로 연결되도록 하는 데 도움이 되어야 합니다.\nRandomization unit 으로 간주되는 컬럼의 결측률과 패턴을 항상 확인해야 합니다. (결측 데이터는 null, 빈 문자열, 0, 무한대 또는 기본값으로 표시될 수 있습니다.) 누락된 데이터는 로깅 문제로 인해 특정 데이터 소스에서 발생하거나 데이터 쿠킹 파이프라인에서 유발될 수 있습니다. 예를 들어 특정 빌드 버전 또는 부분 지연이 있는 데이터 소스에서 누락된 데이터를 탐지할 수 있습니다. 경우에 따라 세션 및 사용자와 같은 여러 집계 수준에서 A/B 테스트 데이터를 분석할 수 있는데, 이때에도 필요한 집계 수준 열이 모두 있는지 확인해야 합니다.\nTreatment assignment 실험한 feature 의 효과를 비교하기 위해 실험군과 대조군 사이의 데이터를 구별하기 위해서는 Treatment assignment (할당) 정보가 필요합니다. 분석에 사용되는 데이터에는 항상 treatment 할당 정보가 들어 있는 컬럼이 있어야 합니다. 또한 이 정보가 동일한 데이터 소스 내에서, 그리고 데이터를 합칠 수도 있는 상황에서는 여러 데이터 소스 간에 일관된 형식을 따르도록 하는 것이 좋습니다.\n또한 treatment assignment 는 분석을 통해 randomization unit (즉, 사용자)에 대해 일관성이 있어야 합니다. 예를 들어 사용자를 실험군에 할당하면 해당 사용자가 대조군에는 나타나지 않아야 합니다.\nTimestamp A/B 테스트 진행 시 관심 이벤트 발생 시간을 추적해야 합니다. 따라서 이벤트의 타임스탬프를 나타내는 열은 항상 있어야 합니다. 타임스탬프는 분석에 포함된 이벤트를 필터링하고 트리거된 분석에 대한 이벤트 순서를 결정하는 데 중요한 역할을 합니다. 또한 결측률을 확인하고 기본 datetime 1900-01-01 및 향후 datetime 과 같은 값을 필터링해야 합니다.\n적절한 타임스탬프를 가급적 제품 맥락에서 선택하는 것이 중요합니다. 일반적으로 선택할 수 있는 타임스탬프는 두 개 이상으로, 활동이 발생한 시간과 해당 로그가 수신된 시간이 포함됩니다. 웹 기반 서버 측 A/B 테스트의 경우 시간 차이가 크지 않을 수 있으며 활동 순서는 변경되지 않습니다.\n그러나 클라이언트 측 A/B 테스트의 경우 이 두 타임스탬프는 상당히 다를 수 있습니다. 어떤 것을 사용할지 결정하는 것은 제품 팀이 주관적으로 절충하지만, 이전 경험으로 볼 때 클라이언트가 반환한 타임스탬프는 종종 노이즈가 심합니다. 클라이언트 로그 타임스탬프보다는 로그를 받을 때 타임스탬프를 사용하는 것이 좋습니다. 아래는 디바이스에서 기록한 이벤트 시간(클라이언트 시간)과 정확한 이벤트 시간이 어떻게 크게 다를 수 있는지를 보여 주는 예시입니다.\nSegments 분석을 위해 종종 데이터를 하위 그룹으로 나눕니다. 이러한 하위 그룹을 Segment (세그먼트) 라고 부르고 다양한 수준의 집합으로 정의합니다. 세그먼트는 행 레벨일 수도 있고 적용 가능한 경우 임의 추출 단위 레벨일 수도 있습니다. 예를 들어 A/B 테스트가 사용자 수준에서 랜덤 추출된 경우 날짜 세그먼트를 행 레벨에, 사용자 레벨에서 사용자 연령 그룹 세그먼트를 가질 수 있습니다. 일부 일반적인 세그먼트에는 날짜, 시장, 브라우저, 앱 버전 등이 포함됩니다.\n세그먼트로 사용되는 열은 올바른 형식이어야 하며 허용 가능한 결측률 및 합리적인 Cardinality (카디널리티)를 가져야 합니다. 경험적으로 합리적인 카디널리티 범위는 2부터 10까지입니다. 수백 개의 고유한 값을 갖는 것은 느린 계산, 낮은 통계 검정력과 시각화 관련 로드 또는 응답 문제와 같은 광범위한 문제를 야기할 수 있습니다. 이러한 세그먼트는 더 많은 수의 하위 그룹을 생성할 수 있습니다. 세그먼트 열이 자연스럽게 높은 카디널리티를 갖는 경우 (예를 들어 언어), 일반적으로 채택되는 방법은 가장 높은 빈도를 기준으로 Top N 으로 자르고 나머지를 \u0026lsquo;기타\u0026rsquo;로 변환하는 것입니다.\n 데이터 퀄리티를 꾸준히 모니터링할 수 있는 방법은? 데이터 퀄리티는 시간이 지남에 따라, 제품과 데이터 소스가 진화함에 따라 변합니다. 데이터 거버넌스에 대한 새로운 요구사항에 따라 새로운 로그를 추가하고, 새로운 데이터 소스를 가져오면 데이터 퀄리티에 영향을 미칠 수 있습니다. 데이터 퀄리티 측정을 추적하는 데 사용할 수 있는 도구는 다음과 같이 여러가지가 있습니다.\n1. Dashboard for data quality metrics 주기적으로 데이터를 수집해야 합니다. 수집 빈도는 시간별, 일별, 주별 또는 사용자 지정 빈도일 수 있습니다. 데이터 퀄리티의 변화 빈도와, 계산 및 스토리지 비용 예산에 따라 달라집니다.\n2. Alerting on anomalies 이상 징후에 대한 경고를 설정하면 데이터 퀄리티를 측정하는 메트릭의 비정상적인 변화를 탐지하는 데 도움이 될 수 있습니다. 소스 데이터 또는 처리 파이프라인의 비정상적인 작업을 나타낼 수 있습니다.\n3. Segment data quality metrics 데이터 퀄리티를 측정하는 메트릭은 일반적인 메트릭과 마찬가지로 동일한 세그먼트를 기준으로 계산해야 합니다. 때로는 세그먼트 내에서 데이터 퀄리티가 크게 저하될 수 있지만 전체적으로는 차이가 거의 없을 수 있습니다.\n4. A/A test A/A 테스트는 실험군과 대조군에서 동일한 경험을 갖는 A/B 테스트입니다. A/A 테스트 실행은 A/B 테스트 시스템의 end-to-end 테스트에 권장되는 접근 방식이며 데이터 퀄리티 문제를 파악하는 데 도움이 될 수 있습니다.\nA/A 테스트는 통계적으로 유의한 메트릭 변경 없이 variants 간 트래픽 분할을 균형 있게 수행할 것입니다. SRM 또는 예기치 않은 메트릭 이동이 있는 경우는 원격 측정 또는 데이터 파이프라인 구현 관련 문제 때문일 수 있습니다.\n아래는 Microsoft 팀이 모니터링을 위해 위의 처음 3가지 도구를 실제 사용하는 방법을 보여주는 예시입니다. 대시보드(파란색 선)는 시간 경과에 따른 데이터 퀄리티 메트릭의 값 변화를 보여 줍니다. 빨간색 지점은 제품 팀에게 경고할 이상 징후를 강조합니다. 하위 그룹의 데이터 퀄리티를 보장하기 위해, 시장 및 OS 버전과 같은 부분에 대해서도 동일한 대시보드를 설정합니다.\n 마치며 데이터 퀄리티는 신뢰할 수 있는 A/B 테스트 결과를 위한 기본 구성 요소입니다. 데이터 퀄리티 문제로 인해 신뢰할 수 없는 A/B 테스트 결과는 의사결정에 부정적인 영향을 미칠 수 있습니다.\nMicrosoft 에서는 데이터 퀄리티 확인을 위해 항상 위의 4가지 도구를 활용해 모니터링을 지속합니다. 이번 글에서 소개한 데이터 퀄리티 체크리스트 및 중요 데이터 필드 요구사항을 활용해, 각자의 조직에서 A/B 테스트 데이터에 대한 점검을 해봐도 좋을 것 같습니다.\n References [1] A. Fabijan et al., “Diagnosing Sample Ratio Mismatch in A/B Testing.” https://www.microsoft.com/en-us/research/group/experimentation-platform-exp/articles/diagnosing-sample-ratio-mismatch-in-a-b-testing/\n[2] R. Kohavi, D. Tang, and Y. Xu, Trustworthy Online Controlled Experiments: A Practical Guide to A/B Testing. Cambridge University Press, 2020.\n[3] W. Machmouchi, S. Gupta, and R. Zhang, “Patterns of Trustworthy Experimentation: During-Experiment Stage.” https://www.microsoft.com/en-us/research/group/experimentation-platform-exp/articles/patterns-of-trustworthy-experimentation-during-experiment-stage/\n[4] Janhavie, “Data Quality.” https://medium.com/datacrat/data-quality-dc4018fc443\n[5] Lean-Data, “Here is how to start with data quality.” https://www.lean-data.nl/data-quality/here-is-how-to-start-with-data-quality/\n[6] T. Crook, B. Frasca, R. Kohavi, and R. Longbotham, “Seven pitfalls to avoid when running controlled experiments on the web,” in Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining – KDD ’09, Paris, France, 2009, p. 1105. doi: 10.1145/1557019.1557139.\n","permalink":"https://koolganni.github.io/posts/experiment/data-quality/","summary":"A/B 테스트와 같은 제품 실험을 자주 실행하는 조직일수록, 실험 분석 결과에 따라 다음 액션이 빠르게 결정됩니다. 실험 분석에서 가장 중요한 것은 무엇일까요? Microsoft Research 에서는 신뢰할 수 있는 실험 분석을 위해서는 데이터 퀄리티가 기본적으로 갖춰줘야 한다고 이야기합니다.\n  이 글은 Microsoft Experimentation Platform 팀에서 소개하는 \u0026ldquo;Data Quality: Fundamental Building Blocks for Trustworthy A/B testing Analysis\u0026rdquo; 를 바탕으로 작성되었습니다.\n Introduction 데이터는 기술 산업의 모든 제품 라이프사이클에서 중요한 역할을 합니다.","title":"신뢰할 수 있는 실험 분석을 위해 데이터 퀄리티 챙기기"},{"content":" 추천 시스템의 성능은 어떻게 평가할까요? 어떤 추천 시스템인지에 따라 방법은 다양할 것입니다. 이번 글에서는 대표적인 정량적 평가 지표 MAP, NDCG, RMSE 에 대해 알아보겠습니다.\n 좋은 추천 시스템이란 추천 시스템의 성능, 다시 말해 사용자에게 얼마나 적절한 아이템을 추천했는지를 우리는 어떻게 평가할 수 있을까요? 서비스 관점에서는 추천 시스템을 적용하기 전과 후의 제품 매출이나 구독 등 실제 수익이 얼마나 향상되었는지를 확인해 볼 수 있을 것입니다. 혹은 A/B Test 와 같은 대조실험을 통해 어떤 추천 방법이 더 나은 고객 반응을 이끌었는지 비교해 볼 수 있을 것입니다.\n기술 관점에서는 정량적인 평가로 추천 시스템의 성능을 예측해 볼 수 있습니다. 추천 시스템이 풀고자 하는 문제는 크게 Ranking 문제와 예측 문제로 나뉘어집니다. Ranking 문제의 경우 사용자에게 추천한 아이템 순서와 실제 사용자가 선택한 아이템 순서를 비교해보는 등 사용자-아이템 데이터를 기반으로 성능을 평가할 수 있습니다. 그럼 그 예로 MAP 지표부터 알아보겠습니다.\n MAP (Mean Average Precision) 먼저, Precision 개념에 대해 간단히 살펴보겠습니다.\n→ Positive 로 예측된 것들 중 실제 Positive 의 비율을 의미하며\n→ 사용자에게 추천한 아이템들 중 실제로 사용자가 관심을 보인 아이템의 비율로 생각할 수 있습니다.\n단순히 이 비율만을 사용한다면 아이템을 추천한 순서는 전혀 상관쓰지 않는다는 것을 알 수 있습니다. 하지만 추천 시스템의 Ranking 문제는 순서(순위)가 매우 중요합니다. MAP는 순서를 반영해 Precision을 측정합니다.\n영화 추천 플랫폼에서 사용자에게 영화 3가지를 추천해준다고 가정해봅시다.\n   Recommendations Precision@k (k=3) AP@k (k=3)     [0, 0, 1] [0, 0, 1/3] (1/3)*(1/3) = 0.11   [0, 1, 1] [0, 1/2, 2/3] (1/3)*(1/2 + 2/3) = 0.38   [1, 1, 0] [1/1, 2/2, 2/3] (1/3)*(1/1 + 2/2 + 2/3) = 0.89   [1, 1, 1] [1/1, 2/2, 3/3] (1/3)*(1/1 + 2/2 + 3/3) = 1     Recommendations : 추천을 했는데 맞은 경우 1, 틀리면 0 Precision@k : 추천한 k개의 영화의 Precision  Recommendations 와 같은 index 까지의 영화를 추천했을 때 Precision 값   AP@k : Precision@k를 평균낸 값  위 표를 보면 [0, 1, 1] 과 [1, 1, 0] 추천과 같이 동일한 양의 아이템에 대해 추천을 성공한 경우에도 그 아이템이 좀 더 앞에 배치될수록 높은 AP 점수가 나오는 것을 확인할 수 있습니다.\n그럼 마지막으로 MAP의 M 은 무엇을 의미할까요? 예를 들어 위 표의 각 행을 사용자 1명이라고 한다면, 총 4개의 AP 즉, 4명의 사용자의 AP를 평균낸 값을 우리는 MAP@k (k=4) 로 표현할 수 있습니다.\n NDCG (Normalized Discounted Cumulative Gain) MAP와 마찬가지로 랭킹 추천에 사용되는 평가 지표로 단순한 랭킹이 아닌 사용자와 아이템의 관련성을 반영한 지표입니다. 기존에 정보 검색 (Information Retrieval) 분야에서 많이 사용되었습니다. NDCG를 이해하기 위해서는 먼저 CG와 DCG를 이해할 필요가 있습니다.\n✔️ CG (Cumulative Gain) Cumulative Gain은 상위 n 개의 추천 아이템의 각 관련성(relevance score)을 모두 합한 값입니다. 이때 relevance score 란 단순히 사용자와 관련이 있는지 여부 (binary) 혹은 문제에 따라 세분화된 값을 가질 수 있습니다. 아래 예시에서는 관련이 있음, 다시 말해 아이템에 대한 사용자의 선호도를 1, 2, 3 순으로 커지도록 설정했고 동일한 비중으로 더하여 CG를 구했습니다.\nSet A, B 가 각각 추천된 아이템 목록이라고 한다면, Set B 에서 선호도가 높은 아이템이 더 먼저 추천되었으므로 성능이 더 뛰어나다고 할 수 있습니다. 하지만 이 둘의 CG 값은 동일하므로 CG 자체만으로는 성능 평가를 하기 어렵습니다. 따라서 먼저 위치한 relevance score 가 CG에 더 많은 영향을 줄 수 있도록 할인(Discount)의 개념을 도입하는데, 그것이 바로 DCG (Discounted Cumulative Gain)입니다.\n✔️ DCG (Discounted Cumulative Gain) Discounted Cumulative Gain은 상위 n 개의 추천 아이템의 각 relevance score 를 log(i+1) 로 나누어 먼저 추천이 될수록 분모의 값이 작아지는, 다시 말해 CG에 추천 순서의 가중치를 반영합니다.\nSet A 보다 Set B 의 DCG 값이 더 높게 산출된 것을 확인할 수 있습니다.\n하지만 DCG는 사용자마다 추천해주는 아이템의 개수가 다를 경우 명확한 평가가 어렵습니다. 예를 들어 영상 추천 플랫폼에서 하루에 30개의 영상을 소비하는 사용자와 3개의 영상을 소비하는 사용자에게 제공되는 추천 아이템의 개수는 다르고 이 개수에 따라 DCG 값 또한 달라질 것입니다.\n따라서 DCG에는 적절한 상한 및 하한 점수가 필요합니다. 모든 추천 점수를 평균하여 최종 점수에 대해 정규화할 필요가 있습니다. 이를 반영한 것이 NDCG (Normalized Discounted Cumulative Gain)입니다.\nNormalized Discounted Cumulative Gain은 DCG 값을 iDCG 값으로 나눈 것으로 이때 iDCG는 이상적인(identical) DCG를 의미합니다. 다시 말해 기존 DCG의 relevance score 순서가 [2, 3, 3, 1, 2] 라면 iDCG의 relevance score 순서는 [3, 3, 2, 2, 1] 이 되는 것입니다.\n이렇게 계산된 NDCG는 0 에서 1 사이의 값을 가지며 이 값이 1에 가까울수록 모델의 성능이 좋은 것임을 알 수 있습니다.\n RMSE (Root Mean Squared Error) 추천 시스템의 예측 문제에서 사용되는 평가 지표입니다. 영화에 대한 사용자의 평점을 예측하는 경우를 예로 들면 실제 평점과 모델의 예측 평점의 차이를 하나의 평균 제곱근 오차로 나타냅니다.\n오차를 제곱함으로써 더 큰 오차를 만들고, 제곱근으로 원래 scale 의 의미있는 숫자로 돌아갑니다.\nRMSE는 Scale-dependent 한 특성을 가지고 있습니다. 다시 말해 예측 대상 값에 영향을 받습니다. 예를 들어 같은 0.01의 에러도 10개의 아이템 중에서 추천을 했을 때와 100개의 아이템 중에서 추천을 했을 때, 즉 어떤 y_pred와 y_actual을 사용했느냐에 따라 다른 의미를 갖습니다.\n또한 RMSE 값이 낮을수록 모델의 성능이 더 좋다고 정량적으로 평가는 가능하나 꼭 좋은 추천임을 보장할 수 있는 것은 아닙니다. 아래와 같이 사용자의 영화 평점을 예측하는 모델 A 와 B 의 RMSE를 비교하는 상황을 가정해보겠습니다.\n    Model A Model B y_actual     Movie 1 3.5 4 5   Movie 2 3.5 1 3   Movie 3 3.5 5 4.5   Movie 4 3.5 2 4   Movie 5 3.5 3 2   RMSE 1.2 2.05     위 표를 보면 RMSE 값이 더 낮은 Model A 의 성능이 더 좋은 것을 확인할 수 있습니다. 하지만 실제로 Model A 가 더 좋은 추천을 해주었다고 이야기할 수 있을까요? 어떤 영화든 3.5점으로 예측하는 Model A 에 비해서 Movie 1을 4점으로 예측해 실제 5점을 받은 Model B 가 \u0026ldquo;높은 점수로 추천된 영화 중 괜찮은 영화가 있었다.\u0026ldquo;는 피드백을 받을수도 있을 것입니다.\n따라서 이러한 극단적인 경우를 포함해서 RMSE는 추천 시스템의 절대적인 좋고 나쁨의 기준이 아닌 어느 정도 성능이 나오는지에 대한 객관적인 평가로 사용하는 것이 적합하다고 할 수 있습니다.\n References  https://youtu.be/m4SNL-ZUTaA https://towardsdatascience.com/evaluate-your-recommendation-engine-using-ndcg-759a851452d1 https://github.com/jaewonlee-728/fastcampus-RecSys  ","permalink":"https://koolganni.github.io/posts/rec-sys/evaluation-metric/","summary":"추천 시스템의 성능은 어떻게 평가할까요? 어떤 추천 시스템인지에 따라 방법은 다양할 것입니다. 이번 글에서는 대표적인 정량적 평가 지표 MAP, NDCG, RMSE 에 대해 알아보겠습니다.\n 좋은 추천 시스템이란 추천 시스템의 성능, 다시 말해 사용자에게 얼마나 적절한 아이템을 추천했는지를 우리는 어떻게 평가할 수 있을까요? 서비스 관점에서는 추천 시스템을 적용하기 전과 후의 제품 매출이나 구독 등 실제 수익이 얼마나 향상되었는지를 확인해 볼 수 있을 것입니다. 혹은 A/B Test 와 같은 대조실험을 통해 어떤 추천 방법이 더 나은 고객 반응을 이끌었는지 비교해 볼 수 있을 것입니다.","title":"[추천 시스템] 추천 시스템의 성능 평가"},{"content":" 가설 검정을 하다보면 95%의 신뢰구간, 99%의 신뢰구간을 이야기할 때가 많습니다. 여기서 신뢰구간이란 정확히 무엇을 의미하는 것일까요?\n 신뢰구간과 신뢰도의 의미 먼저, 표본의 정보를 활용해 모집단의 특징을 추측하는 것을 우리는 \u0026lsquo;추정\u0026rsquo;이라고 합니다.\n모집단의 특징 중에서 모집단의 평균, 즉 모평균(μ)을 추정하는 상황을 가정해봅시다.\n예를 들어 모집단의 평균 나이가 30일 때 모평균이 1 ≤ μ ≤ 100 추정범위 안에 들어가는지 추측하는 것은 100% 확실한 추정입니다. 하지만 모평균으로 추정될 수 있는 값이 매우 많기 때문에 추정의 가치가 없다고 할 수 있습니다.\n반대로 모평균을 28 ≤ μ ≤ 32 와 같이 범위를 줄여서 추정한다면 오차가 생길 가능성이 높아지지만 추정될 수 있는 값이 몇 개 없으므로 추정으로서의 가치가 높습니다.\n이처럼 유용한 추정범위를 우리는 신뢰구간(Confidence Interval)이라 하고, 그 추정범위를 어느 정도 믿을 수 있는지에 대한 정도를 신뢰도(Confidence Level)라고 합니다.\n 신뢰구간을 구하는 방법 신뢰도는 꼭 정해진 것은 아니지만 보통 95%, 99% 를 많이 사용합니다. 95%의 신뢰도는 5%의 유의수준(⍺)을 의미하고 99%의 신뢰도는 1%의 유의수준(⍺)을 의미합니다.\n평균이 0, 표준편차가 1인 표준정규분포표를 활용하면 95% 신뢰도의 신뢰구간에 대해 다음과 같은 식을 도출할 수 있습니다.\n P(0 ≤ Z ≤ 1.96) = 0.475   P(-1.96 ≤ Z ≤ 1.96) = 0.95  여기서 Z 를 다음과 같이 풀어서 쓸 수 있습니다.\n최종적으로 유도된 식은 크기가 n 인 표본의 평균이 x̄ 일 때, 모평균 μ 에 대한 신뢰도 95%의 신뢰구간을 의미합니다.\n즉, 해당 추정범위 안에 모평균 μ 가 존재할 것으로 추정하는 것입니다.\n이때 σ 는 모집단의 표준편차를 의미하는데, 사실적으로 모집단의 평균과 분산을 알기 어렵기 때문에 추정 과정에서는 모표준편차 σ 대신 표본의 표준편차 S 를 이용합니다.\n 신뢰도, 표본의 개수, 표본표준편차에 따른 신뢰구간의 변화 1. 95%, 99% 신뢰도의 신뢰구간이 모두 표본의 개수(n)가 같은 경우  99% 신뢰도의 신뢰구간의 길이가 더 깁니다. 모평균이 99% 신뢰도의 신뢰구간에 포함될 확률이 커집니다. 오차가 생길 가능성이 낮지만 추정의 가치 또한 낮습니다.  2. 95% 신뢰도의 같은 신뢰구간에서 표본의 개수(n \u0026lt; m)가 다를 경우  개수가 m 인 표본의 신뢰구간의 길이가 더 짧습니다. 표본의 개수가 커질수록 신뢰구간의 길이가 짧아집니다. 오차가 생길 가능성이 있지만 추정의 가치가 높습니다.  3. 95% 신뢰도의 같은 신뢰구간에서 표본의 표준편차(S1 \u0026lt; S2)가 다를 경우  표준편차가 S2 인 표본의 신뢰구간의 길이가 더 깁니다. 표본의 분산이 커질수록 신뢰구간의 길이가 길어집니다. 오차가 생길 가능성이 낮지만 추정의 가치 또한 낮습니다.   그럼 모평균의 신뢰도 95%의 신뢰구간이란? 모평균을 추정할 때 우리는 여러 표본들을 사용합니다. 이때 표본들은 서로 다른 평균, 표준편차를 갖고 있습니다.\n다시 말해 각 표본마다 신뢰구간의 위치와 길이가 모두 다릅니다.\n따라서 모평균 μ 의 신뢰도 95%의 신뢰구간의 의미는 다음과 같습니다.\n 크기가 n 인 표본을 계속 (임의로) 추출해서 신뢰구간을 구하는 일을 반복한다면, 그 신뢰구간의 95% 정도가 모평균 μ 를 포함합니다.\n 정리하면 95%의 신뢰도 기준으로 100개의 표본 중 95개의 표본의 신뢰구간에 포함된 μ 가 모평균이 될 것이라 추정하는 것입니다.\n 🤖 추천 시스템에서 신뢰구간을 활용한 예시 https://tv.kakao.com/v/413991950 (27:00~)\n References  https://youtu.be/1WSTBVFeQ-4 https://nulib.github.io/moderndive_book/10-CIs.html https://saylordotorg.github.io/text_introductory-statistics/s11-01-large-sample-estimation-of-a-p.html  ","permalink":"https://koolganni.github.io/posts/statistics/confidence-interval/","summary":"가설 검정을 하다보면 95%의 신뢰구간, 99%의 신뢰구간을 이야기할 때가 많습니다. 여기서 신뢰구간이란 정확히 무엇을 의미하는 것일까요?\n 신뢰구간과 신뢰도의 의미 먼저, 표본의 정보를 활용해 모집단의 특징을 추측하는 것을 우리는 \u0026lsquo;추정\u0026rsquo;이라고 합니다.\n모집단의 특징 중에서 모집단의 평균, 즉 모평균(μ)을 추정하는 상황을 가정해봅시다.\n예를 들어 모집단의 평균 나이가 30일 때 모평균이 1 ≤ μ ≤ 100 추정범위 안에 들어가는지 추측하는 것은 100% 확실한 추정입니다. 하지만 모평균으로 추정될 수 있는 값이 매우 많기 때문에 추정의 가치가 없다고 할 수 있습니다.","title":"신뢰구간 (Confidence Interval)"},{"content":" LightGBM XGBoost와 같은 Gradient Boosting Decision Tree (GBDT) 기반 앙상블 모델은 Kaggle Competition 상위권 팀에서 많이 사용하는 모델로 유명합니다. 이번 글에서는 Decision Tree 분류 모델에 대해 알아보겠습니다.\n Decision Tree Decision Tree (의사결정 나무)는 데이터에 내재되어 있는 패턴을 예측 가능한 분류 규칙들의 조합으로 나타내어 목표 변수에 대한 분류(Classification) 또는 예측(Regression)을 수행하는 기법입니다. 질문을 던지면서 찾고자 하는 대상을 좁혀나가는 일련의 필터링 과정 혹은 스무고개 놀이와 비슷한 개념으로 아래 그림과 같이 트리의 형태를 가지고 있습니다.\n위 예시는 타이타닉호 탑승객의 생존 여부를 나타내는 Decision Tree 로 각 내부 노드들은 하나의 입력 변수에, 자식 노드들로 이어지는 가지들은 입력 변수에 의해 분기되는 두 개의 영역으로 대응됩니다.\n아래 그림은 입력 변수 𝑿1 과 𝑿2 에 대한 규칙에 의해 데이터가 𝑹1 ~ 𝑹5 영역으로 분리되는 것을 확인할 수 있습니다.\n이때 어떤 순서로 변수들을 사용하는지에 따라 여러 Decision Tree 를 생성할 수 있습니다. 그렇다면 우리는 어떤 방법으로 더 좋은 Decision Tree 를 만들 수 있을까요? 답은 변별력이 더 좋은 질문을 먼저 찾는 것에 있습니다.\n여기서 불순도 (Impurity)라는 개념을 활용합니다. 이는 노드에 여러 범주가 섞여 있는 것을 의미합니다. Decision Tree 분류 모델은 이러한 불순도를 측정하는 대표적인 지표 Entropy (엔트로피), Gini Impurity (지니 불순도)를 비용 함수로 사용해 불순도를 최소화하는 방향으로 트리의 가지 분할을 진행합니다.\n Entropy 정보 이론(Information Theory)에서 Entropy (엔트로피)는 어떤 사건의 불확실성을 의미합니다. 예를 들어 어떤 사건이 발생할 확률이 낮을수록 어떤 정보일지는 불확실하게 되고 이때 우리는 정보가 많다 혹은 엔트로피가 높다고 표현합니다. 확률에 대한 엔트로피 공식은 아래와 같습니다.\n 𝒑 는 어떤 사건이 일어날 확률입니다. 𝒃 는 로그의 base 로 보통 2 가 사용됩니다.  확률에 대한 엔트로피를 그래프로 그려보면 확률이 낮을수록 엔트로피는 높아지고 확률이 높을수록 엔트로피는 낮아지는 것을 확인할 수 있습니다. 즉, 엔트로피를 감소시키는 것은 사건의 불확실성을 줄이면서 분류/예측이 확실해지는 것으로 이야기할 수 있겠습니다.\n다수의 사건 다시 말해 범주(클래스)가 존재하는 엔트로피에 대한 공식은 아래와 같습니다.\n Cross Entropy (교차 엔트로피) 라고도 말합니다. Decision Tree 에서는 이진 트리를 사용하기 때문에 이진 로그를 사용하며 딥러닝에서는 보통 자연 로그를 사용합니다.  예를 들어 A, B, C, D 클래스를 분류하는 Decision Tree 를 만든다고 가정해봅시다. 아래와 같이 분류된 3가지 결과에 대해 각각 엔트로피를 구해보겠습니다.\nBucket1 에서는 8개의 데이터 모두 A 클래스에 속하는 데이터입니다. 이때 𝒑 는 8/8 = 1 이 되므로 엔트로피는 0 입니다.\nBucket2 와 Bucket3 에서는 8개의 데이터 중 A, B, C, D 클래스가 혼재되어 있습니다. 공식에 따라 엔트로피를 구하면 아래와 같습니다.\nA 클래스로 분류된 데이터만 존재하는 다시 말해 불순도가 0 인 Bucket1 의 엔트로피가 가장 낮으며 A, B, C, D 클래스가 동일한 비율로 존재하는 Bucket3 의 엔트로피가 가장 높은 것을 확인할 수 있습니다.\n Gini Impurity Gini Impurity (지니 불순도)는 어떤 데이터 집합에서 무작위로 라벨(클래스)을 추정할 때 틀릴 확률을 말합니다. 집합에 있는 항목이 모두 같다면 지니 불순도는 최솟값 0 을 갖게 되며 해당 집합은 순도가 높다 혹은 완전히 순수하다고 할 수 있습니다. 확률에 대한 지니 불순도 공식은 아래와 같습니다.\n예를 들어 Chest Pain 유무(True/False)에 따라 심장병이 있는지 혹은 없는지를 분류한다고 가정해봅시다. 총 303명의 환자를 아래와 같이 분류했습니다.\nChest Pain 이 있을 때 지니 불순도를 구하면 아래와 같습니다.\n반대로 Chest Pain 이 없을 때 지니 불순도는 아래와 같습니다.\n이때 Chest Pain 변수가 가지는 (Chest Pain 유무에 따른) 2가지의 지니 불순도는 각각 144개, 159개의 데이터로부터 나타내는 것이기 때문에 둘을 단순히 합해서 사용할 수는 없습니다.\n따라서 Chest Pain 이라는 입력 변수에 대한 지니 불순도는 아래와 같이 지니 불순도의 가중합을 활용해서 구할 수 있습니다.\n 𝑰(𝑫 left) 와 𝑰(𝑫 right) 는 왼쪽 노드와 오른쪽 노드의 지니 불순도를 의미합니다. (𝒏 left)/𝑵𝓶 와 (𝒏 right)/𝑵𝓶 는 전체 데이터에서 차지하는 왼쪽 노드 데이터의 비율과 오른쪽 노드 데이터의 비율을 의미합니다.  이와 동일한 과정으로 Good Blood Circulation 그리고 Blocked Arteries 변수에 대한 지니 불순도를 구하면 아래와 같습니다.\n데이터가 가지는 세 가지 변수 중 지니 불순도가 가장 낮은 것은 Good Blood Circulation 으로 해당 변수가 트리의 루트 노드로 가장 적합하다는 것을 알 수 있습니다.\n추가적으로 지니 불순도는 로그 계산이 필요한 엔트로피보다 연산량이 적습니다. scikit-learn 에서는 기본적으로 지니 불순도를 활용한 CART 알고리즘 기반의 Decision Tree 모듈을 제공합니다.\n Information Gain (IG) 지니 불순도는 가중합을 활용해 트리를 분리시킬 입력 변수를 선택한다면 엔트로피는 Information Gain (정보 획득)을 활용합니다.\nscikit-learn 의 DecisionTreeClassifier 모듈은 트리 분리 기준을 의미하는 criterion 파라미터로 앞서 말한 지니 불순도 그리고 엔트로피에 대한 Information Gain을 제공합니다.\n정보 이론에서 Information Gain (정보 획득)이란 주어진 정보로 인해 확률변수의 불확실성이 얼마나 감소했는지를 나타내는 지표입니다. 즉, 특정 변수를 사용했을 때 불순도의 감소량을 의미합니다.\n위 공식과 같이 𝑰𝑮 (Information Gain) 은 부모 노드의 데이터셋 𝑫𝑝 를 입력 변수 𝒇 로 분리했을 때 부모 노드의 불순도에서 모든 자식 노드의 불순도를 뺀 값입니다.\n예를 들어 환자의 Symptom A, B, C 유무(True/False)에 따라 질병이 있는지 혹은 없는지를 분류하는 Decision Tree 를 만든다고 가정해봅시다.\n세 가지의 독립 변수 중에서 어떤 변수를 루트 노드로 하는 것이 좋을지 Information Gain 을 구해 비교해봅시다. 먼저 변수를 선택하기 전의 엔트로피와 Symptom A 로 데이터를 분리했을 때 엔트로피를 계산하면 아래와 같습니다.\n👉 Symptom A 변수에 대한 Information Gain 은 0.971 에서 0.951 을 뺀 값인 0.02 가 됩니다.\n동일한 방법으로 Symptom B 변수에 대한 IG 는 0.419 그리고 Symptom C 변수에 대한 IG 는 0.171 로 구할 수 있습니다. 최종적으로 이 데이터에서는 IG 값이 가장 큰 다시 말해 엔트로피 감소량이 가장 큰 Symptom A 가 트리의 첫번째 분리 기준이 되는 것이 적합하다고 말할 수 있습니다.\n이러한 Information Gain 은 ID3 와 C4.5 그리고 C5.0 알고리즘 기반의 Decision Tree 에서 불순도 측도로 사용됩니다.\n 모델의 학습 Decision Tree 의 학습은 학습에 사용되는 데이터 집합을 적절한 분할 기준에 따라 부분 집합들로 나누는 과정입니다. 이때 분할 기준의 예시로는 앞서 살펴본 지니 불순도와 엔트로피가 있겠습니다.\n분할 과정은 각각의 나눠진 자료 부분 집합에 재귀적으로 반복되며 분할로 인해 더 이상 새로운 예측 값이 추가되지 않거나 부분 집합의 노드가 목표 변수와 같은 값을 지닐 때까지 계속됩니다.\n이러한 하향식 결정 트리 귀납법(top-down induction of decision trees, TDIDT)은 Greedy(탐욕) 알고리즘의 한 예시이며 데이터로부터 결정 트리를 학습하는 가장 일반적인 방법입니다.\n다만 한 가지 주의할 점은 트리의 분기가 너무 많다면 학습 데이터에 오버피팅 할 위험이 있습니다. 결정 트리의 분기 수가 일정 수준 이상이 되면 새로운 데이터에 대해 분류가 잘되지 않는 현상이 발생합니다. 따라서 검증 데이터에 대한 오분류율이 증가하는 시점에서 적절한 가지치기 (Pruning)를 수행해야 합니다.\n결정 트리는 가지치기 (Pruning)의 비용 함수를 최소로 하는 분기를 찾아내도록 학습됩니다. 비용 함수식은 아래와 같습니다.\n 𝑪𝑪(𝑻) : 결정 트리의 비용 복잡도 𝑬𝑹𝑹(𝑻) : 검증 데이터에 대한 오분류율 𝑳(𝑻) : 단말 노드의 수 (구조의 복잡도) 𝜶 : 하이퍼파라미터로 보통 0.01 에서 0.1 사이의 값   모델의 한계 Decision Tree 모델은 한 개의 변수만을 선택하기 때문에 데이터의 특성이 해당 변수에 의해 수직 혹은 수평적으로 구분되지 못할 때 분류율이 떨어지고 트리가 복잡해지는 문제가 발생합니다. 앞서 살펴본 가지치기의 비용 함수에서 확인할 수 있듯이 단말 노드의 수가 증가할수록 오버피팅 위험이 있습니다.\n또한 학습 데이터의 미세한 변동에도 최종 결과가 크게 영향을 받습니다. 예를 들어 두 변수가 비슷한 수준의 정보력을 갖지만, 약간의 차이에 의해 다른 변수가 선택되면 이후 트리 구성이 크게 달라질 수 있기 때문입니다.\n이러한 결정 트리의 한계를 보완하기 위해 랜덤 포레스트 (Random Forest)모델은 같은 데이터에 대해 결정 트리를 여러 개 만들어서 그 결과를 집계해 예측 성능을 높입니다.\n References  의사결정나무모델 1 (모델개요, 예측나무) - 고려대 김성범 교수님 의사결정나무모델 2 (분류나무, Information Gain) - 고려대 김성범 교수님 결정 트리 학습법 - 위키백과 정보 엔트로피 - 위키백과 https://medium.com/udacity/shannon-entropy-information-gain-and-picking-balls-from-buckets-5810d35d54b4 Decision Trees - StatQuest with Josh Starmer https://en.wikipedia.org/wiki/Information_gain_in_decision_trees  ","permalink":"https://koolganni.github.io/posts/machine-learning/decision-tree/","summary":"LightGBM XGBoost와 같은 Gradient Boosting Decision Tree (GBDT) 기반 앙상블 모델은 Kaggle Competition 상위권 팀에서 많이 사용하는 모델로 유명합니다. 이번 글에서는 Decision Tree 분류 모델에 대해 알아보겠습니다.\n Decision Tree Decision Tree (의사결정 나무)는 데이터에 내재되어 있는 패턴을 예측 가능한 분류 규칙들의 조합으로 나타내어 목표 변수에 대한 분류(Classification) 또는 예측(Regression)을 수행하는 기법입니다. 질문을 던지면서 찾고자 하는 대상을 좁혀나가는 일련의 필터링 과정 혹은 스무고개 놀이와 비슷한 개념으로 아래 그림과 같이 트리의 형태를 가지고 있습니다.","title":"의사결정 나무 (Decision Tree)"},{"content":" 이진 분류 (Binary Classification) 문제에서 좋은 성능을 보이며 동시에 딥러닝에서 중요한 개념을 포함하고 있는 로지스틱 회귀(분류)에 대해 알아보겠습니다.\n Binary Classification 스팸 메일과 스팸이 아닌 메일, 긍정 리뷰와 부정 리뷰, 악성 종양과 양성 종양 등 두 가지 선택지 중에서 하나를 예측하는 것을 우리는 이진 분류(Binary Classification)라고 합니다.\n이진 분류 문제를 해결하기 위해서는 어떤 모델을 사용해야 할까요? 아래와 같이 종양의 크기에 따라 악성(1)인지 양성(0)인지 분류하는 선형 회귀 모델을 만든다고 가정해봅시다.\n𝒚 축의 0.5 를 기준으로 𝒙 를 나눈다면 악성 종양과 양성 종양을 잘 구분하는 것으로 보입니다. 이때 모델의 데이터에 아주 큰 종양이 하나 더 추가되는 상황을 생각해봅시다.\n아래와 같이 녹색 선의 함수는 새로운 데이터에 대한 손실을 줄이기 위해 아래로 기울어진 형태로 업데이트 될 것이고 같은 𝒚 축의 0.5 를 기준으로 했을 때 이전과 달리 분류가 제대로 되지 않을 것입니다.\n또한 선형 회귀 모델의 가설 함수는 𝒙 값에 따라 결과가 1 보다 매우 크거나 0 보다 매우 작은 값을 내보낼 수도 있습니다. 따라서 이진 분류 문제에서는 단순한 직선 형태의 선형 회귀 모델은 적합하지 않으며 𝒙 값이 아무리 크거나 작아도 예측한 결과가 0 과 1 사이로 제한되는 가설 함수를 사용해야 합니다.\n Sigmoid function (Logistic function) 로지스틱 회귀 (Logistic Regression) 모델은 시그모이드 함수 (로지스틱 함수)를 사용해 선형 함수를 0 과 1 사이의 값만 내보내는 함수로 변환합니다.\n시그모이드 함수는 아래 그래프와 같이 0 과 1 사이의 값을 가지면서 S 자 형태로 그려집니다.\n𝒛가 학습된 로지스틱 회귀 모델의 선형 레이어의 출력을 나타낸다면 sigmoid(𝒛)는 0 과 1 사이의 값으로 자세히는 True 일 확률값을 생성합니다. 수식으로 나타내면 아래와 같습니다.\n 𝒚' 은 로지스틱 회귀 모델의 출력입니다.  0 ≦ 𝒚' ≦ 1 𝒚' 이 0.7 이라면 True 일 확률이 70% 이며 False 일 확률이 30% 라는 의미입니다.   𝒛 = 𝒃 + 𝑾1·𝒙1 + 𝑾2·𝒙2 + \u0026hellip; 𝑾𝑛·𝒙𝑛  𝑾 값은 모델의 학습된 가중치이고 𝒃 는 편향입니다. 𝒙 값은 특성 값입니다.   𝒚' 이 0.7 이고 기준값(threshold)이 0.5 라면 𝒙 를 1(True)로 분류합니다. 반대로 𝒚' 이 0.3 이라면 0(False)으로 분류합니다.  이처럼 로지스틱 회귀 모델은 선형 회귀식 𝒛를 시그모이드 함수를 통해 0 과 1 사이의 확률값으로 예측하도록 만든 모델임을 알 수 있습니다.\n추가적으로 시그모이드 함수식이 유도된 과정을 살펴보겠습니다. 베르누이 시행1에서 1 이 나올 확률 μ 와 0 이 나올 확률 1 - μ 의 비율을 승산비(Odds Ratio)라고 합니다.\n승산비를 로그 변환한 것이 로지트 함수(Logit function)입니다.\n로지트 함수는 입력 값(μ)의 범위가 [0, 1] 이고 출력 값(𝒛)의 범위는 로그 변환에 의해 [-∞, +∞] 입니다. 시그모이드 함수 (로지스틱 함수)는 이러한 로지트 함수의 역함수입니다.\n즉, [-∞, +∞] 범위의 값(𝒛)을 가지는 입력변수를 [0, 1] 범위의 값(확률)을 가지는 출력변수로 변환한 것입니다.\n이러한 시그모이드 함수는 딥러닝에서 각 클래스의 확률값을 계산하기 위해 출력층의 활성화 함수로도 많이 사용됩니다.\n Cost function Linear Regression 의 비용 함수 (목적 함수)는 아래 그래프와 같이 볼록한 모양으로 어느 지점에서 시작하는지에 상관 없이 경사 하강법을 통해 전역 최솟값을 찾습니다.\n하지만 Logistic Regression의 비용 함수는 같은 MSE (Mean Squared Error) 로 정의할 경우 아래 그래프와 같이 구부러진 모양이 되어 어느 지점에서 시작하는지에 따라 전역 최솟값을 찾지 못하고 지역 최솟값에 머무를 가능성이 있습니다.\n따라서 Logistic Regression의 비용 함수는 아래와 같이 제곱 손실이 아닌 로그 손실로 정의합니다. 실제 𝒚 = 1 일 때와 𝒚 = 0 일 때 서로 다른 비용 함수를 따르게 됩니다.\n실제 𝒚 = 1 일 때 로지스틱 회귀 모델이 예측한 확률값이 1 에 가까울수록 손실은 0 에 가까워지는 것을 확인할 수 있습니다. 반대로 실제 𝒚 = 0 일 때 모델이 예측한 확률값이 0 에 가까울수록 손실은 0 에 가까워지는 것을 확인할 수 있습니다.\n또한 𝒚 는 오직 1 또는 0 값만 가지므로 아래와 같이 비용 함수를 하나의 식으로도 표현할 수 있습니다. 이 함수는 크로스 엔트로피 (Cross Entropy) 함수라고 합니다.2\n θ 는 𝒉(𝒙) 의 가중치 및 편향 파라미터를 의미합니다.  따라서 모든 훈련 데이터에 대한 Logistic Regression의 최종적인 비용 함수는 아래와 같이 정의됩니다. 이는 결국 크로스 엔트로피 손실을 최소화하는 것으로 MLE (Maximum Likelihood Estimation)를 구하는 과정과 동일합니다.3\n References  https://developers.google.com/machine-learning/crash-course/logistic-regression/ 모두를 위한 딥러닝 강좌 시즌 1 https://www.boostcourse.org/ai222/lecture/24525/ https://www.geeksforgeeks.org/ml-cost-function-in-logistic-regression/    임의의 결과가 \u0026lsquo;Yes\u0026rsquo; 또는 \u0026lsquo;No\u0026rsquo; 의 두 가지 중 하나인 실험 \u0026#x21a9;\u0026#xfe0e;\n Entropy : 이산확률변수의 불확실성 정도 \u0026#x21a9;\u0026#xfe0e;\n Likelihood : 사건이 발생할 가능성으로 확률(Probability)과 달리 \u0026lsquo;추론\u0026rsquo;의 개념 \u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://koolganni.github.io/posts/machine-learning/logistic-regression/","summary":"이진 분류 (Binary Classification) 문제에서 좋은 성능을 보이며 동시에 딥러닝에서 중요한 개념을 포함하고 있는 로지스틱 회귀(분류)에 대해 알아보겠습니다.\n Binary Classification 스팸 메일과 스팸이 아닌 메일, 긍정 리뷰와 부정 리뷰, 악성 종양과 양성 종양 등 두 가지 선택지 중에서 하나를 예측하는 것을 우리는 이진 분류(Binary Classification)라고 합니다.\n이진 분류 문제를 해결하기 위해서는 어떤 모델을 사용해야 할까요? 아래와 같이 종양의 크기에 따라 악성(1)인지 양성(0)인지 분류하는 선형 회귀 모델을 만든다고 가정해봅시다.","title":"로지스틱 회귀 (Logistic Regression)"}]