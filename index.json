[{"content":" Attention 과 장기의존성 Self-Attention  Attention 과 장기의존성 RNN 모델은 시퀀스 데이터를 처리할 수 있다는 장점이 있지만 동시에 \u0026lsquo;장기 의존성 (Long-term dependency)\u0026rsquo; 문제 또한 가지고 있다.\n장기 의존성 문제 (Long-term dependency)란, 시퀀스 즉 문장이 길어질수록 이전 단어의 정보를 잃어버려 정보의 손실이 발생하는 것을 의미한다. 이러한 문제를 해결하기 위해 과거 정보와 현재 정보를 적절히 조절해 활용하는 LSTM, LSTM 의 간소화 버전 GRU 모델이 나왔다.\n하지만 LSTM, GRU 모델로도 해결할 수 없는 문제가 있다. 바로 문장이 길어질수록 모든 단어 정보를 고정 길이의 Hidden State Vector 에 담을 수 없다는 것이다. 즉, 입력 문장이 길어질수록 성능이 떨어지는 문제는 여전히 존재하는 것이다.\n따라서 Attention모델은 Hidden State Vector 를 늘려 이 문제를 해결한다. 문장의 입력 단어마다 Hidden State Vector 를 간직하도록 한다. 입력 단어가 N개라면 N개의 Hidden State Vector 를 갖는 것이다.\n영한 번역을 해야 하는 상황을 가정해보자. 영어 문장이 인코더에 들어와 디코더에 한글 문장을 출력해야 한다고 하자.\n디코더에서는 한글 단어를 생성할 때마다 해당 단어가 인코더에서 넘어온 모든 영어 단어의 Hidden State Vector 와 얼마나 연관이 있는지 Attention 점수를 구한다. 구하는 과정은 다음과 같다.\n 인코더의 각 단어 별 Hidden State Vector 와 디코더의 Hidden State Vector 준비 인코더의 각 Hidden State Vector 와 디코더의 Hidden State Vector 를 내적해서 입력 단어 별 가중치 score 계산 가중치 score 에 대해 softmax 함수 처리 → 각 단어가 디코더에서 생성할 단어와 얼마나 연관이 있는지에 대한 가중치 분포 3번에서 구한 softmax score 와 각 단어의 Hidden State Vector 를 가중합 4번에서 구한 Context Vector 를 기반으로 디코더 단어 출력  이러한 과정을 통해 Attention 모델은 매번 하나의 단어를 출력할 때마다 문장의 모든 단어를 가지고 어떤 인코더 Hidden State Vector 와 연관이 있는지, 즉 어떤 단어에 집중(Attention)해야 하는지 알 수 있다.\n다시 말해, 문장의 모든 정보를 매번 활용함으로써 장기 의존성 문제를 해결한다.\nSelf-Attention \u0026hellip;\n References\n  https://medium.datadriveninvestor.com/attention-in-rnns-321fbcd64f05 https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/  ","permalink":"https://koolganni.github.io/posts/attention_model/","summary":"Attention 과 장기의존성 Self-Attention  Attention 과 장기의존성 RNN 모델은 시퀀스 데이터를 처리할 수 있다는 장점이 있지만 동시에 \u0026lsquo;장기 의존성 (Long-term dependency)\u0026rsquo; 문제 또한 가지고 있다.\n장기 의존성 문제 (Long-term dependency)란, 시퀀스 즉 문장이 길어질수록 이전 단어의 정보를 잃어버려 정보의 손실이 발생하는 것을 의미한다. 이러한 문제를 해결하기 위해 과거 정보와 현재 정보를 적절히 조절해 활용하는 LSTM, LSTM 의 간소화 버전 GRU 모델이 나왔다.\n하지만 LSTM, GRU 모델로도 해결할 수 없는 문제가 있다.","title":"Attention is All You Need"},{"content":"Hugo + Github Pages 조합으로 블로그를 만들었다.\n깔끔한 테마에 필요한 기능들만 딱 있어서 좋다.\n앞으로 노션, 미디엄에 정리해둔 글들 틈틈이 옮겨봐야지!\n","permalink":"https://koolganni.github.io/posts/test/","summary":"Hugo + Github Pages 조합으로 블로그를 만들었다.\n깔끔한 테마에 필요한 기능들만 딱 있어서 좋다.\n앞으로 노션, 미디엄에 정리해둔 글들 틈틈이 옮겨봐야지!","title":"새 블로그 시작"}]