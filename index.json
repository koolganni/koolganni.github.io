[{"content":" 추천 시스템의 성능은 어떻게 평가할까요? 어떤 추천 시스템인지에 따라 방법은 다양할 것입니다. 이번 글에서는 대표적인 정량적 평가 지표 MAP, NDCG, RMSE 에 대해 알아보겠습니다.\n 좋은 추천 시스템이란 추천 시스템의 성능, 다시 말해 사용자에게 얼마나 적절한 아이템을 추천했는지를 우리는 어떻게 평가할 수 있을까요? 서비스 관점에서는 추천 시스템을 적용하기 전과 후의 제품 매출이나 구독 등 실제 수익이 얼마나 향상되었는지를 확인해 볼 수 있을 것입니다. 혹은 A/B Test 와 같은 대조실험을 통해 어떤 추천 방법이 더 나은 고객 반응을 이끌었는지 비교해 볼 수 있을 것입니다.\n기술 관점에서는 정량적인 평가로 추천 시스템의 성능을 예측해 볼 수 있습니다. 추천 시스템이 풀고자 하는 문제는 크게 Ranking 문제와 예측 문제로 나뉘어집니다. Ranking 문제의 경우 사용자에게 추천한 아이템 순서와 실제 사용자가 선택한 아이템 순서를 비교해보는 등 사용자-아이템 데이터를 기반으로 성능을 평가할 수 있습니다. 그럼 그 예로 MAP 지표부터 알아보겠습니다.\n MAP (Mean Average Precision) 먼저, Precision 개념에 대해 간단히 살펴보겠습니다.\n→ Positive 로 예측된 것들 중 실제 Positive 의 비율을 의미하며\n→ 사용자에게 추천한 아이템들 중 실제로 사용자가 관심을 보인 아이템의 비율로 생각할 수 있습니다.\n단순히 이 비율만을 사용한다면 아이템을 추천한 순서는 전혀 상관쓰지 않는다는 것을 알 수 있습니다. 하지만 추천 시스템의 Ranking 문제는 순서(순위)가 매우 중요합니다. MAP는 순서를 반영해 Precision을 측정합니다.\n영화 추천 플랫폼에서 사용자에게 영화 3가지를 추천해준다고 가정해봅시다.\n   Recommendations Precision@k (k=3) AP@k (k=3)     [0, 0, 1] [0, 0, 1/3] (1/3)*(1/3) = 0.11   [0, 1, 1] [0, 1/2, 2/3] (1/3)*(1/2 + 2/3) = 0.38   [1, 1, 0] [1/1, 2/2, 2/3] (1/3)*(1/1 + 2/2 + 2/3) = 0.89   [1, 1, 1] [1/1, 2/2, 3/3] (1/3)*(1/1 + 2/2 + 3/3) = 1     Recommendations : 추천을 했는데 맞은 경우 1, 틀리면 0 Precision@k : 추천한 k개의 영화의 Precision  Recommendations 와 같은 index 까지의 영화를 추천했을 때 Precision 값   AP@k : Precision@k를 평균낸 값  위 표를 보면 [0, 1, 1] 과 [1, 1, 0] 추천과 같이 동일한 양의 아이템에 대해 추천을 성공한 경우에도 그 아이템이 좀 더 앞에 배치될수록 높은 AP 점수가 나오는 것을 확인할 수 있습니다.\n그럼 마지막으로 MAP의 M 은 무엇을 의미할까요? 예를 들어 위 표의 각 행을 사용자 1명이라고 한다면, 총 4개의 AP 즉, 4명의 사용자의 AP를 평균낸 값을 우리는 MAP@k (k=4) 로 표현할 수 있습니다.\n NDCG (Normalized Discounted Cumulative Gain) MAP와 마찬가지로 랭킹 추천에 사용되는 평가 지표로 단순한 랭킹이 아닌 사용자와 아이템의 관련성을 반영한 지표입니다. 기존에 정보 검색 (Information Retrieval) 분야에서 많이 사용되었습니다. NDCG를 이해하기 위해서는 먼저 CG와 DCG를 이해할 필요가 있습니다.\n✔️ CG (Cumulative Gain) Cumulative Gain은 상위 n 개의 추천 아이템의 각 관련성(relevance score)을 모두 합한 값입니다. 이때 relevance score 란 단순히 사용자와 관련이 있는지 여부 (binary) 혹은 문제에 따라 세분화된 값을 가질 수 있습니다. 아래 예시에서는 관련이 있음, 다시 말해 아이템에 대한 사용자의 선호도를 1, 2, 3 순으로 커지도록 설정했고 동일한 비중으로 더하여 CG를 구했습니다.\nSet A, B 가 각각 추천된 아이템 목록이라고 한다면, Set B 에서 선호도가 높은 아이템이 더 먼저 추천되었으므로 성능이 더 뛰어나다고 할 수 있습니다. 하지만 이 둘의 CG 값은 동일하므로 CG 자체만으로는 성능 평가를 하기 어렵습니다. 따라서 먼저 위치한 relevance score 가 CG에 더 많은 영향을 줄 수 있도록 할인(Discount)의 개념을 도입하는데, 그것이 바로 DCG (Discounted Cumulative Gain)입니다.\n✔️ DCG (Discounted Cumulative Gain) Discounted Cumulative Gain은 상위 n 개의 추천 아이템의 각 relevance score 를 log(i+1) 로 나누어 먼저 추천이 될수록 분모의 값이 작아지는, 다시 말해 CG에 추천 순서의 가중치를 반영합니다.\nSet A 보다 Set B 의 DCG 값이 더 높게 산출된 것을 확인할 수 있습니다.\n하지만 DCG는 사용자마다 추천해주는 아이템의 개수가 다를 경우 명확한 평가가 어렵습니다. 예를 들어 영상 추천 플랫폼에서 하루에 30개의 영상을 소비하는 사용자와 3개의 영상을 소비하는 사용자에게 제공되는 추천 아이템의 개수는 다르고 이 개수에 따라 DCG 값 또한 달라질 것입니다.\n따라서 DCG에는 적절한 상한 및 하한 점수가 필요합니다. 모든 추천 점수를 평균하여 최종 점수에 대해 정규화할 필요가 있습니다. 이를 반영한 것이 NDCG (Normalized Discounted Cumulative Gain)입니다.\nNormalized Discounted Cumulative Gain은 DCG 값을 iDCG 값으로 나눈 것으로 이때 iDCG는 이상적인(identical) DCG를 의미합니다. 다시 말해 기존 DCG의 relevance score 순서가 [2, 3, 3, 1, 2] 라면 iDCG의 relevance score 순서는 [3, 3, 2, 2, 1] 이 되는 것입니다.\n이렇게 계산된 NDCG는 0 에서 1 사이의 값을 가지며 이 값이 1에 가까울수록 모델의 성능이 좋은 것임을 알 수 있습니다.\n RMSE (Root Mean Squared Error) 추천 시스템의 예측 문제에서 사용되는 평가 지표입니다. 영화에 대한 사용자의 평점을 예측하는 경우를 예로 들면 실제 평점과 모델의 예측 평점의 차이를 하나의 평균 제곱근 오차로 나타냅니다.\n오차를 제곱함으로써 더 큰 오차를 만들고, 제곱근으로 원래 scale 의 의미있는 숫자로 돌아갑니다.\nRMSE는 Scale-dependent 한 특성을 가지고 있습니다. 다시 말해 예측 대상 값에 영향을 받습니다. 예를 들어 같은 0.01의 에러도 10개의 아이템 중에서 추천을 했을 때와 100개의 아이템 중에서 추천을 했을 때, 즉 어떤 y_pred와 y_actual을 사용했느냐에 따라 다른 의미를 갖습니다.\n또한 RMSE 값이 낮을수록 모델의 성능이 더 좋다고 정량적으로 평가는 가능하나 꼭 좋은 추천임을 보장할 수 있는 것은 아닙니다. 아래와 같이 사용자의 영화 평점을 예측하는 모델 A 와 B 의 RMSE를 비교하는 상황을 가정해보겠습니다.\n    Model A Model B y_actual     Movie 1 3.5 4 5   Movie 2 3.5 1 3   Movie 3 3.5 5 4.5   Movie 4 3.5 2 4   Movie 5 3.5 3 2   RMSE 1.2 2.05     위 표를 보면 RMSE 값이 더 낮은 Model A 의 성능이 더 좋은 것을 확인할 수 있습니다. 하지만 실제로 Model A 가 더 좋은 추천을 해주었다고 이야기할 수 있을까요? 어떤 영화든 3.5점으로 예측하는 Model A 에 비해서 Movie 1을 4점으로 예측해 실제 5점을 받은 Model B 가 \u0026ldquo;높은 점수로 추천된 영화 중 괜찮은 영화가 있었다.\u0026ldquo;는 피드백을 받을수도 있을 것입니다.\n따라서 이러한 극단적인 경우를 포함해서 RMSE는 추천 시스템의 절대적인 좋고 나쁨의 기준이 아닌 어느 정도 성능이 나오는지에 대한 객관적인 평가로 사용하는 것이 적합하다고 할 수 있습니다.\n References  https://youtu.be/m4SNL-ZUTaA https://towardsdatascience.com/evaluate-your-recommendation-engine-using-ndcg-759a851452d1 https://github.com/jaewonlee-728/fastcampus-RecSys  ","permalink":"https://koolganni.github.io/posts/rec-sys/evaluation-metric/","summary":"추천 시스템의 성능은 어떻게 평가할까요? 어떤 추천 시스템인지에 따라 방법은 다양할 것입니다. 이번 글에서는 대표적인 정량적 평가 지표 MAP, NDCG, RMSE 에 대해 알아보겠습니다.\n 좋은 추천 시스템이란 추천 시스템의 성능, 다시 말해 사용자에게 얼마나 적절한 아이템을 추천했는지를 우리는 어떻게 평가할 수 있을까요? 서비스 관점에서는 추천 시스템을 적용하기 전과 후의 제품 매출이나 구독 등 실제 수익이 얼마나 향상되었는지를 확인해 볼 수 있을 것입니다. 혹은 A/B Test 와 같은 대조실험을 통해 어떤 추천 방법이 더 나은 고객 반응을 이끌었는지 비교해 볼 수 있을 것입니다.","title":"[추천 시스템] 추천 시스템의 성능 평가"},{"content":" 가설 검정을 하다보면 95%의 신뢰구간, 99%의 신뢰구간을 이야기할 때가 많습니다. 여기서 신뢰구간이란 정확히 무엇을 의미하는 것일까요?\n 신뢰구간과 신뢰도의 의미 먼저, 표본의 정보를 활용해 모집단의 특징을 추측하는 것을 우리는 \u0026lsquo;추정\u0026rsquo;이라고 합니다.\n모집단의 특징 중에서 모집단의 평균, 즉 모평균(μ)을 추정하는 상황을 가정해봅시다.\n예를 들어 모집단의 평균 나이가 30일 때 모평균이 1 ≤ μ ≤ 100 추정범위 안에 들어가는지 추측하는 것은 100% 확실한 추정입니다. 하지만 모평균으로 추정될 수 있는 값이 매우 많기 때문에 추정의 가치가 없다고 할 수 있습니다.\n반대로 모평균을 28 ≤ μ ≤ 32 와 같이 범위를 줄여서 추정한다면 오차가 생길 가능성이 높아지지만 추정될 수 있는 값이 몇 개 없으므로 추정으로서의 가치가 높습니다.\n이처럼 유용한 추정범위를 우리는 신뢰구간(Confidence Interval)이라 하고, 그 추정범위를 어느 정도 믿을 수 있는지에 대한 정도를 신뢰도(Confidence Level)라고 합니다.\n 신뢰구간을 구하는 방법 신뢰도는 꼭 정해진 것은 아니지만 보통 95%, 99% 를 많이 사용합니다. 95%의 신뢰도는 5%의 유의수준(⍺)을 의미하고 99%의 신뢰도는 1%의 유의수준(⍺)을 의미합니다.\n평균이 0, 표준편차가 1인 표준정규분포표를 활용하면 95% 신뢰도의 신뢰구간에 대해 다음과 같은 식을 도출할 수 있습니다.\n P(0 ≤ Z ≤ 1.96) = 0.475   P(-1.96 ≤ Z ≤ 1.96) = 0.95  여기서 Z 를 다음과 같이 풀어서 쓸 수 있습니다.\n최종적으로 유도된 식은 크기가 n 인 표본의 평균이 x̄ 일 때, 모평균 μ 에 대한 신뢰도 95%의 신뢰구간을 의미합니다.\n즉, 해당 추정범위 안에 모평균 μ 가 존재할 것으로 추정하는 것입니다.\n이때 σ 는 모집단의 표준편차를 의미하는데, 사실적으로 모집단의 평균과 분산을 알기 어렵기 때문에 추정 과정에서는 모표준편차 σ 대신 표본의 표준편차 S 를 이용합니다.\n 신뢰도, 표본의 개수, 표본표준편차에 따른 신뢰구간의 변화 1. 95%, 99% 신뢰도의 신뢰구간이 모두 표본의 개수(n)가 같은 경우  99% 신뢰도의 신뢰구간의 길이가 더 깁니다. 모평균이 99% 신뢰도의 신뢰구간에 포함될 확률이 커집니다. 오차가 생길 가능성이 낮지만 추정의 가치 또한 낮습니다.  2. 95% 신뢰도의 같은 신뢰구간에서 표본의 개수(n \u0026lt; m)가 다를 경우  개수가 m 인 표본의 신뢰구간의 길이가 더 짧습니다. 표본의 개수가 커질수록 신뢰구간의 길이가 짧아집니다. 오차가 생길 가능성이 있지만 추정의 가치가 높습니다.  3. 95% 신뢰도의 같은 신뢰구간에서 표본의 표준편차(S1 \u0026lt; S2)가 다를 경우  표준편차가 S2 인 표본의 신뢰구간의 길이가 더 깁니다. 표본의 분산이 커질수록 신뢰구간의 길이가 길어집니다. 오차가 생길 가능성이 낮지만 추정의 가치 또한 낮습니다.   그럼 모평균의 신뢰도 95%의 신뢰구간이란? 모평균을 추정할 때 우리는 여러 표본들을 사용합니다. 이때 표본들은 서로 다른 평균, 표준편차를 갖고 있습니다.\n다시 말해 각 표본마다 신뢰구간의 위치와 길이가 모두 다릅니다.\n따라서 모평균 μ 의 신뢰도 95%의 신뢰구간의 의미는 다음과 같습니다.\n 크기가 n 인 표본을 계속 (임의로) 추출해서 신뢰구간을 구하는 일을 반복한다면, 그 신뢰구간의 95% 정도가 모평균 μ 를 포함합니다.\n 정리하면 95%의 신뢰도 기준으로 100개의 표본 중 95개의 표본의 신뢰구간에 포함된 μ 가 모평균이 될 것이라 추정하는 것입니다.\n 🤖 추천 시스템에서 신뢰구간을 활용한 예시 https://tv.kakao.com/v/413991950 (27:00~)\n References  https://youtu.be/1WSTBVFeQ-4 https://nulib.github.io/moderndive_book/10-CIs.html https://saylordotorg.github.io/text_introductory-statistics/s11-01-large-sample-estimation-of-a-p.html  ","permalink":"https://koolganni.github.io/posts/statistics/confidence-interval/","summary":"가설 검정을 하다보면 95%의 신뢰구간, 99%의 신뢰구간을 이야기할 때가 많습니다. 여기서 신뢰구간이란 정확히 무엇을 의미하는 것일까요?\n 신뢰구간과 신뢰도의 의미 먼저, 표본의 정보를 활용해 모집단의 특징을 추측하는 것을 우리는 \u0026lsquo;추정\u0026rsquo;이라고 합니다.\n모집단의 특징 중에서 모집단의 평균, 즉 모평균(μ)을 추정하는 상황을 가정해봅시다.\n예를 들어 모집단의 평균 나이가 30일 때 모평균이 1 ≤ μ ≤ 100 추정범위 안에 들어가는지 추측하는 것은 100% 확실한 추정입니다. 하지만 모평균으로 추정될 수 있는 값이 매우 많기 때문에 추정의 가치가 없다고 할 수 있습니다.","title":"신뢰구간 (Confidence Interval)"},{"content":" 머신 러닝 그리고 딥러닝 모델 학습의 목표는 더 정확한 예측을 위해 최적의 가중치와 편향을 찾는 것입니다. 이를 위한 방법으로 주로 사용되는 경사 하강법에 대해 알아보겠습니다.\n 비용 함수 (Cost Function) X 축은 입력값이고 Y 축은 목푯값입니다. 이때 X 를 입력하면 Y 를 예측하여 출력하는 모델을 만든다고 가정해봅시다. 머신 러닝에서 𝑊 는 가중치 벡터를 의미하고 𝑏 는 편향을 나타냅니다.\n위 그림에서는 3가지 선들 중 파란색 선이 모든 데이터 세트를 정확하게 예측한 것으로 보입니다. 이러한 선을 우리는 어떻게 찾을 수 있을까요?\n모델의 예측이 얼마나 잘못되었는지를 나타내는 수 손실을 활용할 수 있습니다. 예를 들어 아래 그림의 왼쪽은 손실이 큰 모델이고 오른쪽은 손실이 작은 모델입니다.\n모델을 훈련시킬 때에는 하나의 예시가 아니라 전체 데이터 세트에서 손실을 최소화해야 합니다. 따라서 개별 손실을 종합할 수 있는 비용 함수 (손실 함수)를 사용합니다.\n비용 함수는 임의의 함수를 사용할 수도 있지만 일반적으로는 평균 제곱 오차(MSE)와 교차 엔트로피 오차(CEE)를 사용합니다. 이번 글에서는 평균 제곱 오차를 기준으로 살펴보겠습니다.\n평균 제곱 오차는 N개의 데이터의 평균 제곱 손실(L2 손실)입니다. 개별 제곱 손실을 모두 합한 다음 평균을 구합니다.\n위에서 살펴본 선형 회귀 모델의 MSE 비용 함수를 생각해보겠습니다. 아래와 같이 우리는 선형 회귀 모델의 가중치(𝑊), 편향(𝑏) 매개변수에 대한 비용 함수를 구해야 합니다.\n그럼 이러한 비용 함수, 즉 손실을 최소화하는 모델의 매개변수는 어떻게 찾을 수 있을까요? 전체 데이터 세트에 대해 모든 매개변수의 비용 함수를 계산하는 것은 매우 비효율적인 방법입니다. 따라서 머신 러닝에서는 더 나은 방법인 경사 하강법을 활용합니다.\n 경사 하강법 (Gradient Descent) 회귀 문제에서는 가중치(𝑊)에 대한 비용 함수를 그리면 아래와 같이 항상 볼록 함수 모양을 갖습니다.\n볼록 문제에서는 기울기가 정확하게 0인 지점인 최소값이 하나만 존재합니다. 이 최소값이 손실 함수가 수렴하는 값이며 동시에 우리가 찾고자 하는 손실을 최소화하는 지점입니다.\n경사 하강법은 가중치(𝑊) 값 변화에 따른 손실 함수값의 변화를 측정하기 위해 미분을 활용합니다. 미분을 통해 한 점에 대한 접선의 기울기를 알면 어느 방향으로 점을 움직여야 함수값이 감소 혹은 증가하는지 알 수 있기 때문입니다.\n위 그림에서 초록색 선은 𝑊 가 임의의 값을 가지게 되는 경우에 대해서 그래프 상으로 접선의 기울기를 보여줍니다. 주목할 것은 맨 아래의 볼록한 부분으로 갈수록 접선의 기울기가 점차 작아지다가 결국 cost 가 최소화되는 지점에서는 0 이 된다는 것입니다.\n즉, 경사 하강법의 아이디어는 비용 함수를 미분하여 현재 𝑊 에서의 접선의 기울기를 구하고 기울기가 낮은 방향으로 (0 인 곳을 향해) 𝑊 값을 변경하는 작업을 반복하는 것에 있습니다.\n𝑊 를 업데이트하는 식은 아래와 같습니다.\n현재 𝑊 에서의 접선의 기울기와 ⍺(Learning rate)를 곱한 값을 현재 𝑊 에서 빼서 새로운 𝑊 로 업데이트하는 것을 의미합니다.\n ⍺(Learning rate) : 𝑊 를 얼마나 크게 변경할지 결정합니다. ⍺ 가 지나치게 높다면 𝑊 값이 발산할 수 있고 반대로 지나치게 낮다면 학습 속도가 느려집니다.  이 식에 따라 접선의 기울기가 음수인 경우에는 𝑊 값이 증가하게 되는데 결과적으로 접선의 기울기가 0 인 방향으로 𝑊 값이 조정됩니다.\n반대로 접선의 기울기가 양수인 경우에는 𝑊 값이 감소하게 되고 이 또한 결과적으로 접선의 기울기가 0 인 방향으로 𝑊 값이 조정됩니다.\n이러한 과정을 통해 경사 하강법은 전체 데이터 세트에 대해 동시에 학습이 진행됩니다.\n 확률적 경사 하강법 (Stochastic Gradient Descent) 경사 하강법은 최적의 파라미터를 찾기 위한 좋은 도구이지만 사실 우리가 마주하는 문제는 선형 회귀 모델처럼 볼록 함수가 아닐 때가 많습니다. 특히 신경망의 경우 대부분 아래 그림과 같이 계란판처럼 생긴 비볼록 함수를 보여줍니다.\n비볼록 함수는 시작 위치에 따라 다른 지점을 찾기 때문에 단순한 경사 하강법으로는 전역 최솟값(Global Minimum)을 찾지 못하고 지역 최솟값(Local Minimum)에 빠질 위험이 있습니다.\n확률적 경사 하강법(Stochastic Gradient Descent)은 이러한 문제를 어느 정도 해결해줍니다. 전체 데이터를 가지고 파라미터를 업데이트하는 경사 하강법과 달리 확률적 경사 하강법은 확률적으로 미니 배치를 가지고 파라미터를 업데이트합니다.1\n따라서 비용 함수 그래프의 곡선 모양이 매번 바뀌게 되고 지역 최솟값 부분이 더 이상 기울기가 0 이 되지 않도록 하면서 해당 지점에서 탈출하도록 도와줍니다. 또한 데이터의 일부를 가지고 파라미터를 업데이트하기 때문에 연산 자원을 좀 더 효율적으로 활용합니다.\n이외에도 Momentum, AdaGrad, Adam, RMSprop 등 경사 하강법의 단점을 보완하기 위한 여러 방법들이 있습니다.\n (추가) 경사 하강법의 편미분 계산 과정  θ0(편향)과 θ1(가중치)에 대한 비용 함수 편미분을 통해 파라미터를 업데이트 하는 과정입니다.   References  https://developers.google.com/machine-learning/crash-course/descending-into-ml/ 모두를 위한 딥러닝 강좌 시즌 1 딥러닝을 이용한 자연어 처리 입문 https://www.boostcourse.org/ai222/lecture/24509 밑바닥부터 시작하는 딥러닝 1 - 한빛미디어 (2017)    미니 배치 확률적 경사 하강법에 대한 설명입니다. \u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://koolganni.github.io/posts/machine-learning/gradient-descent/","summary":"머신 러닝 그리고 딥러닝 모델 학습의 목표는 더 정확한 예측을 위해 최적의 가중치와 편향을 찾는 것입니다. 이를 위한 방법으로 주로 사용되는 경사 하강법에 대해 알아보겠습니다.\n 비용 함수 (Cost Function) X 축은 입력값이고 Y 축은 목푯값입니다. 이때 X 를 입력하면 Y 를 예측하여 출력하는 모델을 만든다고 가정해봅시다. 머신 러닝에서 𝑊 는 가중치 벡터를 의미하고 𝑏 는 편향을 나타냅니다.\n위 그림에서는 3가지 선들 중 파란색 선이 모든 데이터 세트를 정확하게 예측한 것으로 보입니다.","title":"경사 하강법 (Gradient Descent)"},{"content":" 이진 분류 (Binary Classification) 문제에서 좋은 성능을 보이며 동시에 딥러닝에서 중요한 개념을 포함하고 있는 로지스틱 회귀(분류)에 대해 알아보겠습니다.\n Binary Classification 스팸 메일과 스팸이 아닌 메일, 긍정 리뷰와 부정 리뷰, 악성 종양과 양성 종양 등 두 가지 선택지 중에서 하나를 예측하는 것을 우리는 이진 분류(Binary Classification)라고 합니다.\n이진 분류 문제를 해결하기 위해서는 어떤 모델을 사용해야 할까요? 아래와 같이 종양의 크기에 따라 악성(1)인지 양성(0)인지 분류하는 선형 회귀 모델을 만든다고 가정해봅시다.\n𝒚 축의 0.5 를 기준으로 𝒙 를 나눈다면 악성 종양과 양성 종양을 잘 구분하는 것으로 보입니다. 이때 모델의 데이터에 아주 큰 종양이 하나 더 추가되는 상황을 생각해봅시다.\n아래와 같이 녹색 선의 함수는 새로운 데이터에 대한 손실을 줄이기 위해 아래로 기울어진 형태로 업데이트 될 것이고 같은 𝒚 축의 0.5 를 기준으로 했을 때 이전과 달리 분류가 제대로 되지 않을 것입니다.\n또한 선형 회귀 모델의 가설 함수는 𝒙 값에 따라 결과가 1 보다 매우 크거나 0 보다 매우 작은 값을 내보낼 수도 있습니다. 따라서 이진 분류 문제에서는 단순한 직선 형태의 선형 회귀 모델은 적합하지 않으며 𝒙 값이 아무리 크거나 작아도 예측한 결과가 0 과 1 사이로 제한되는 가설 함수를 사용해야 합니다.\n Sigmoid function (Logistic function) 로지스틱 회귀 (Logistic Regression) 모델은 시그모이드 함수 (로지스틱 함수)를 사용해 선형 함수를 0 과 1 사이의 값만 내보내는 함수로 변환합니다.\n시그모이드 함수는 아래 그래프와 같이 0 과 1 사이의 값을 가지면서 S 자 형태로 그려집니다.\n𝒛가 학습된 로지스틱 회귀 모델의 선형 레이어의 출력을 나타낸다면 sigmoid(𝒛)는 0 과 1 사이의 값으로 자세히는 True 일 확률값을 생성합니다. 수식으로 나타내면 아래와 같습니다.\n 𝒚' 은 로지스틱 회귀 모델의 출력입니다.  0 ≦ 𝒚' ≦ 1 𝒚' 이 0.7 이라면 True 일 확률이 70% 이며 False 일 확률이 30% 라는 의미입니다.   𝒛 = 𝒃 + 𝑾1·𝒙1 + 𝑾2·𝒙2 + \u0026hellip; 𝑾𝑛·𝒙𝑛  𝑾 값은 모델의 학습된 가중치이고 𝒃 는 편향입니다. 𝒙 값은 특성 값입니다.   𝒚' 이 0.7 이고 기준값(threshold)이 0.5 라면 𝒙 를 1(True)로 분류합니다. 반대로 𝒚' 이 0.3 이라면 0(False)으로 분류합니다.  이처럼 로지스틱 회귀 모델은 선형 회귀식 𝒛를 시그모이드 함수를 통해 0 과 1 사이의 확률값으로 예측하도록 만든 모델임을 알 수 있습니다.\n추가적으로 시그모이드 함수식이 유도된 과정을 살펴보겠습니다. 베르누이 시행1에서 1 이 나올 확률 μ 와 0 이 나올 확률 1 - μ 의 비율을 승산비(Odds Ratio)라고 합니다.\n승산비를 로그 변환한 것이 로지트 함수(Logit function)입니다.\n로지트 함수는 입력 값(μ)의 범위가 [0, 1] 이고 출력 값(𝒛)의 범위는 로그 변환에 의해 [-∞, +∞] 입니다. 시그모이드 함수 (로지스틱 함수)는 이러한 로지트 함수의 역함수입니다.\n즉, [-∞, +∞] 범위의 값(𝒛)을 가지는 입력변수를 [0, 1] 범위의 값(확률)을 가지는 출력변수로 변환한 것입니다.\n이러한 시그모이드 함수는 딥러닝에서 각 클래스의 확률값을 계산하기 위해 출력층의 활성화 함수로도 많이 사용됩니다.\n Cost function Linear Regression 의 비용 함수 (목적 함수)는 아래 그래프와 같이 볼록한 모양으로 어느 지점에서 시작하는지에 상관 없이 경사 하강법을 통해 전역 최솟값을 찾습니다.\n하지만 Logistic Regression의 비용 함수는 같은 MSE (Mean Squared Error) 로 정의할 경우 아래 그래프와 같이 구부러진 모양이 되어 어느 지점에서 시작하는지에 따라 전역 최솟값을 찾지 못하고 지역 최솟값에 머무를 가능성이 있습니다.\n따라서 Logistic Regression의 비용 함수는 아래와 같이 제곱 손실이 아닌 로그 손실로 정의합니다. 실제 𝒚 = 1 일 때와 𝒚 = 0 일 때 서로 다른 비용 함수를 따르게 됩니다.\n실제 𝒚 = 1 일 때 로지스틱 회귀 모델이 예측한 확률값이 1 에 가까울수록 손실은 0 에 가까워지는 것을 확인할 수 있습니다. 반대로 실제 𝒚 = 0 일 때 모델이 예측한 확률값이 0 에 가까울수록 손실은 0 에 가까워지는 것을 확인할 수 있습니다.\n또한 𝒚 는 오직 1 또는 0 값만 가지므로 아래와 같이 비용 함수를 하나의 식으로도 표현할 수 있습니다. 이 함수는 크로스 엔트로피 (Cross Entropy) 함수라고 합니다.2\n θ 는 𝒉(𝒙) 의 가중치 및 편향 파라미터를 의미합니다.  따라서 모든 훈련 데이터에 대한 Logistic Regression의 최종적인 비용 함수는 아래와 같이 정의됩니다. 이는 결국 크로스 엔트로피 손실을 최소화하는 것으로 MLE (Maximum Likelihood Estimation)를 구하는 과정과 동일합니다.3\n References  https://developers.google.com/machine-learning/crash-course/logistic-regression/ 모두를 위한 딥러닝 강좌 시즌 1 https://www.boostcourse.org/ai222/lecture/24525/ https://www.geeksforgeeks.org/ml-cost-function-in-logistic-regression/    임의의 결과가 \u0026lsquo;Yes\u0026rsquo; 또는 \u0026lsquo;No\u0026rsquo; 의 두 가지 중 하나인 실험 \u0026#x21a9;\u0026#xfe0e;\n Entropy : 이산확률변수의 불확실성 정도 \u0026#x21a9;\u0026#xfe0e;\n Likelihood : 사건이 발생할 가능성으로 확률(Probability)과 달리 \u0026lsquo;추론\u0026rsquo;의 개념 \u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://koolganni.github.io/posts/machine-learning/logistic-regression/","summary":"이진 분류 (Binary Classification) 문제에서 좋은 성능을 보이며 동시에 딥러닝에서 중요한 개념을 포함하고 있는 로지스틱 회귀(분류)에 대해 알아보겠습니다.\n Binary Classification 스팸 메일과 스팸이 아닌 메일, 긍정 리뷰와 부정 리뷰, 악성 종양과 양성 종양 등 두 가지 선택지 중에서 하나를 예측하는 것을 우리는 이진 분류(Binary Classification)라고 합니다.\n이진 분류 문제를 해결하기 위해서는 어떤 모델을 사용해야 할까요? 아래와 같이 종양의 크기에 따라 악성(1)인지 양성(0)인지 분류하는 선형 회귀 모델을 만든다고 가정해봅시다.","title":"로지스틱 회귀 (Logistic Regression)"},{"content":" 모델의 성능을 높이는 데에는 여러 방법이 있습니다. Overfitting(과대적합)을 억제하는 방법 중 L1 정규화 및 L2 정규화 기술에 대해 알아보겠습니다.\n Overfitting 아래 그림의 맨 오른쪽은 모델이 주어진 데이터 세트에 대해 지나치게 많이 학습을 한 Overfitting(과대적합)의 모습을 보여줍니다. 이는 모델이 학습 데이터를 과하게 암기하여 훈련 데이터에 포함된 노이즈까지 학습한 상태라고 해석할 수 있습니다.\n학습 데이터에 모델이 Overfitting 되는 현상은 모델의 성능을 떨어트리는 주요 이슈입니다. 훈련 데이터에 대한 정확도는 높을지라도 새로운 데이터, 즉 검증 데이터나 테스트 데이터에 대해서는 제대로 동작하지 않습니다.\nOverfitting은 주로 매개변수가 많고 표현력이 높은 복잡한 모델이거나 훈련 데이터가 적은 경우에 발생합니다. 따라서 이를 방지하기 위한 방법에는 다음과 같은 방법들이 있습니다.\n 더 많은 데이터를 활용한다. Feature 의 개수를 줄인다. 적절한 파라미터를 선정한다. Regularization (정규화)  이 중 Regularization은 Overfitting 억제를 위해 많이 사용하는 방법으로 학습 과정에서 큰 가중치에 대해서는 그에 상응하는 큰 패널티를 부과하는 방식으로 진행됩니다. 가중치 매개변수의 값이 커서 발생하는 과대적합을 패널티에 의한 가중치 감소(Weight Decay) 를 통해 억제하는 것입니다.\n이러한 가중치에 대한 패널티를 어떤 방식으로 주는지에 따라 L1 Regularization (Lasso), L2 Regularization (Ridge) 크게 두 가지의 방법이 존재합니다.\n L1 Regularization (Lasso) Regularization은 모델을 학습할 때 단순히 손실 뿐만이 아니라 모델의 복잡도를 함께 최소화해 모델이 일반화가 될 수 있도록 합니다. 정규화를 적용한 모델의 학습 최적화 알고리즘은 모델이 데이터에 얼마나 적합한지 측정하는 손실 항과 모델 복잡도를 측정하는 정규화 항의 함수가 됩니다.\n이때 L1 Regularization은 정규화 항을 L1 Norm1 을 기반으로 정의합니다. L1 Norm은 Manhattan distance 로 부르기도 하는데 벡터 a, b 가 있을 때 각 원소들의 차이의 절댓값 총합을 의미합니다.\n따라서 L1 정규화 항은 모든 특성 가중치의 절댓값의 합계로 정의해 모델의 복잡도를 수치화합니다. 아래 식은 기존 비용 함수에 L1 정규화 항을 더한 것입니다.\n ƛ(lambda) : Regularization 의 강도를 결정하는 하이퍼파라미터  L1 정규화를 적용한 비용 함수는 가중치 값에 대한 미분을 통해 가중치에서 일정 상수를 빼는 식으로 가중치를 업데이트합니다.\n최종적으로 모델에서 유용하지 않은 일부 가중치를 0이 되도록 유도할 수 있습니다. 가중치가 정확하게 0일 경우 이것은 모델에서 해당 특성을 삭제하는 것과 같습니다.\n L1 Regularization을 사용하는 Regression 모델을 Lasso Regression 이라고 합니다.   L2 Regularization (Ridge) L2 Regularization은 정규화 항을 L2 Norm을 기반으로 정의합니다. L2 Norm은 Euclidean distance 로 부르기도 하는데 벡터 a, b 가 있을 때 두 벡터의 직선 거리를 의미합니다.\n따라서 L2 정규화 항은 모든 특성 가중치를 제곱한 값의 합계로 정의해 모델의 복잡도를 수치화합니다. 아래 식은 기존 비용 함수에 L2 정규화 항을 더한 것입니다.\nL2 정규화를 적용한 비용 함수는 가중치 값에 대한 미분을 통해 아래와 같은 식으로 가중치를 업데이트합니다. 이때 기존 가중치(θj)에 곱해지는 값은 항상 1 보다 작으므로 최종적으로 가중치는 줄어드는 방향으로 조정되고 특정 가중치가 비이상적으로 커지는 것을 막습니다.\n📌 ƛ(lambda) 값이 너무 높으면 모델은 단순해지지만 일반화가 아니라 Underfitting(과소적합)해질 위험이 있습니다. 반대로 값이 너무 낮으면 모델은 더 복잡해지고 Overfitting(과대적합)해질 위험이 있습니다. 0으로 설정하는 경우 정규화는 완전히 제거되어 가장 높은 수준의 과적합 위험을 갖게 됩니다. 이것은 L1 Regularization 에서도 마찬가지입니다.\n L2 Regularization을 사용하는 Regression 모델을 Ridge Regression 이라고 합니다.   L1 Regularization 🆚 L2 Regularization L1 정규화와 L2 정규화의 가중치 업데이트에 대한 차이점을 좀 더 살펴보겠습니다.\n아래 그림의 초록색 부분은 정규화로 가능한 가중치의 범위를 나타내며 빨간색 부분은 비용 함수로 가운데 점은 전역 최솟값을 만드는 최적의 가중치를 의미합니다. 왼쪽 그림은 L1 정규화 오른쪽 그림은 L2 정규화에 대한 내용입니다.\nL2 정규화로 가능한 가중치의 범위는 원형의 모양으로 일반적으로 비용 함수와의 접선이 축에 위치하지 않기 때문에 가중치가 0이 되지는 않습니다.\nL1 정규화로 가능한 가중치의 범위는 뾰족한 모양으로 비용 함수와의 접선이 축에 위치할 가능성이 높기 때문에 특정 가중치가 0이 될 수 있습니다.\n정리하면 L2 정규화를 적용할 경우 가중치를 0에 가깝게 만들지만 정확이 0이 되지는 않습니다. 즉, 매번 학습을 하면서 가중치의 x% 만큼 제거한다고 생각할 수 있습니다. 때문에 특성의 가중치를 줄여서 좀 더 단순한 모델을 만듦으로써 과대적합을 억제할 수 있습니다. L2 정규화는 단순성을 위한 정규화라고도 합니다.\nL1 정규화를 적용하면 가중치를 정확히 0으로 만들 수 있기 때문에 특정 가중치를 제거할 수 있습니다. 다시 말해 일종의 Feature Selection 을 수행해서 Feature 의 개수를 줄이는 방향으로 과대적합을 억제할 수 있습니다. L1 정규화는 희소성(Sparsity)2을 위한 정규화라고도 합니다.\n References  https://developers.google.com/machine-learning/crash-course/regularization-for-simplicity/l2-regularization https://www.boostcourse.org/ai222/lecture/24509 밑바닥부터 시작하는 딥러닝 1 - 한빛미디어 (2017) https://towardsdatascience.com/regularization-in-deep-learning-l1-l2-and-dropout-377e75acc036    Norm : 벡터의 길이 혹은 크기를 측정하는 방법 \u0026#x21a9;\u0026#xfe0e;\n 0이 많이 있는 자료들을 희소성이 있는 자료라 합니다. \u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://koolganni.github.io/posts/machine-learning/l1-l2-regularization/","summary":"모델의 성능을 높이는 데에는 여러 방법이 있습니다. Overfitting(과대적합)을 억제하는 방법 중 L1 정규화 및 L2 정규화 기술에 대해 알아보겠습니다.\n Overfitting 아래 그림의 맨 오른쪽은 모델이 주어진 데이터 세트에 대해 지나치게 많이 학습을 한 Overfitting(과대적합)의 모습을 보여줍니다. 이는 모델이 학습 데이터를 과하게 암기하여 훈련 데이터에 포함된 노이즈까지 학습한 상태라고 해석할 수 있습니다.\n학습 데이터에 모델이 Overfitting 되는 현상은 모델의 성능을 떨어트리는 주요 이슈입니다. 훈련 데이터에 대한 정확도는 높을지라도 새로운 데이터, 즉 검증 데이터나 테스트 데이터에 대해서는 제대로 동작하지 않습니다.","title":"L1 과 L2 정규화 (Regularization)"}]