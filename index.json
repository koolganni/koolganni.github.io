[{"content":" 추천 시스템의 성능은 어떻게 평가할까요? 어떤 추천 시스템인지에 따라 방법은 다양할 것입니다. 이번 글에서는 대표적인 정량적 평가 지표 MAP, NDCG, RMSE 에 대해 알아보겠습니다.\n 좋은 추천 시스템이란 추천 시스템의 성능, 다시 말해 사용자에게 얼마나 적절한 아이템을 추천했는지를 우리는 어떻게 평가할 수 있을까요? 서비스 관점에서는 추천 시스템을 적용하기 전과 후의 제품 매출이나 구독 등 실제 수익이 얼마나 향상되었는지를 확인해 볼 수 있을 것입니다. 혹은 A/B Test 와 같은 대조실험을 통해 어떤 추천 방법이 더 나은 고객 반응을 이끌었는지 비교해 볼 수 있을 것입니다.\n기술 관점에서는 정량적인 평가로 추천 시스템의 성능을 예측해 볼 수 있습니다. 추천 시스템이 풀고자 하는 문제는 크게 Ranking 문제와 예측 문제로 나뉘어집니다. Ranking 문제의 경우 사용자에게 추천한 아이템 순서와 실제 사용자가 선택한 아이템 순서를 비교해보는 등 사용자-아이템 데이터를 기반으로 성능을 평가할 수 있습니다. 그럼 그 예로 MAP 지표부터 알아보겠습니다.\n MAP (Mean Average Precision) 먼저, Precision 개념에 대해 간단히 살펴보겠습니다.\n→ Positive 로 예측된 것들 중 실제 Positive 의 비율을 의미하며\n→ 사용자에게 추천한 아이템들 중 실제로 사용자가 관심을 보인 아이템의 비율로 생각할 수 있습니다.\n단순히 이 비율만을 사용한다면 아이템을 추천한 순서는 전혀 상관쓰지 않는다는 것을 알 수 있습니다. 하지만 추천 시스템의 Ranking 문제는 순서(순위)가 매우 중요합니다. MAP는 순서를 반영해 Precision을 측정합니다.\n영화 추천 플랫폼에서 사용자에게 영화 3가지를 추천해준다고 가정해봅시다.\n   Recommendations Precision@k (k=3) AP@k (k=3)     [0, 0, 1] [0, 0, 1/3] (1/3)*(1/3) = 0.11   [0, 1, 1] [0, 1/2, 2/3] (1/3)*(1/2 + 2/3) = 0.38   [1, 1, 0] [1/1, 2/2, 2/3] (1/3)*(1/1 + 2/2 + 2/3) = 0.89   [1, 1, 1] [1/1, 2/2, 3/3] (1/3)*(1/1 + 2/2 + 3/3) = 1     Recommendations : 추천을 했는데 맞은 경우 1, 틀리면 0 Precision@k : 추천한 k개의 영화의 Precision  Recommendations 와 같은 index 까지의 영화를 추천했을 때 Precision 값   AP@k : Precision@k를 평균낸 값  위 표를 보면 [0, 1, 1] 과 [1, 1, 0] 추천과 같이 동일한 양의 아이템에 대해 추천을 성공한 경우에도 그 아이템이 좀 더 앞에 배치될수록 높은 AP 점수가 나오는 것을 확인할 수 있습니다.\n그럼 마지막으로 MAP의 M 은 무엇을 의미할까요? 예를 들어 위 표의 각 행을 사용자 1명이라고 한다면, 총 4개의 AP 즉, 4명의 사용자의 AP를 평균낸 값을 우리는 MAP@k (k=4) 로 표현할 수 있습니다.\n NDCG (Normalized Discounted Cumulative Gain) MAP와 마찬가지로 랭킹 추천에 사용되는 평가 지표로 단순한 랭킹이 아닌 사용자와 아이템의 관련성을 반영한 지표입니다. 기존에 정보 검색 (Information Retrieval) 분야에서 많이 사용되었습니다. NDCG를 이해하기 위해서는 먼저 CG와 DCG를 이해할 필요가 있습니다.\n✔️ CG (Cumulative Gain) Cumulative Gain은 상위 n 개의 추천 아이템의 각 관련성(relevance score)을 모두 합한 값입니다. 이때 relevance score 란 단순히 사용자와 관련이 있는지 여부 (binary) 혹은 문제에 따라 세분화된 값을 가질 수 있습니다. 아래 예시에서는 관련이 있음, 다시 말해 아이템에 대한 사용자의 선호도를 1, 2, 3 순으로 커지도록 설정했고 동일한 비중으로 더하여 CG를 구했습니다.\nSet A, B 가 각각 추천된 아이템 목록이라고 한다면, Set B 에서 선호도가 높은 아이템이 더 먼저 추천되었으므로 성능이 더 뛰어나다고 할 수 있습니다. 하지만 이 둘의 CG 값은 동일하므로 CG 자체만으로는 성능 평가를 하기 어렵습니다. 따라서 먼저 위치한 relevance score 가 CG에 더 많은 영향을 줄 수 있도록 할인(Discount)의 개념을 도입하는데, 그것이 바로 DCG (Discounted Cumulative Gain)입니다.\n✔️ DCG (Discounted Cumulative Gain) Discounted Cumulative Gain은 상위 n 개의 추천 아이템의 각 relevance score 를 log(i+1) 로 나누어 먼저 추천이 될수록 분모의 값이 작아지는, 다시 말해 CG에 추천 순서의 가중치를 반영합니다.\nSet A 보다 Set B 의 DCG 값이 더 높게 산출된 것을 확인할 수 있습니다.\n하지만 DCG는 사용자마다 추천해주는 아이템의 개수가 다를 경우 명확한 평가가 어렵습니다. 예를 들어 영상 추천 플랫폼에서 하루에 30개의 영상을 소비하는 사용자와 3개의 영상을 소비하는 사용자에게 제공되는 추천 아이템의 개수는 다르고 이 개수에 따라 DCG 값 또한 달라질 것입니다.\n따라서 DCG에는 적절한 상한 및 하한 점수가 필요합니다. 모든 추천 점수를 평균하여 최종 점수에 대해 정규화할 필요가 있습니다. 이를 반영한 것이 NDCG (Normalized Discounted Cumulative Gain)입니다.\nNormalized Discounted Cumulative Gain은 DCG 값을 iDCG 값으로 나눈 것으로 이때 iDCG는 이상적인(identical) DCG를 의미합니다. 다시 말해 기존 DCG의 relevance score 순서가 [2, 3, 3, 1, 2] 라면 iDCG의 relevance score 순서는 [3, 3, 2, 2, 1] 이 되는 것입니다.\n이렇게 계산된 NDCG는 0 에서 1 사이의 값을 가지며 이 값이 1에 가까울수록 모델의 성능이 좋은 것임을 알 수 있습니다.\n RMSE (Root Mean Squared Error) 추천 시스템의 예측 문제에서 사용되는 평가 지표입니다. 영화에 대한 사용자의 평점을 예측하는 경우를 예로 들면 실제 평점과 모델의 예측 평점의 차이를 하나의 평균 제곱근 오차로 나타냅니다.\n오차를 제곱함으로써 더 큰 오차를 만들고, 제곱근으로 원래 scale 의 의미있는 숫자로 돌아갑니다.\nRMSE는 Scale-dependent 한 특성을 가지고 있습니다. 다시 말해 예측 대상 값에 영향을 받습니다. 예를 들어 같은 0.01의 에러도 10개의 아이템 중에서 추천을 했을 때와 100개의 아이템 중에서 추천을 했을 때, 즉 어떤 y_pred와 y_actual을 사용했느냐에 따라 다른 의미를 갖습니다.\n또한 RMSE 값이 낮을수록 모델의 성능이 더 좋다고 정량적으로 평가는 가능하나 꼭 좋은 추천임을 보장할 수 있는 것은 아닙니다. 아래와 같이 사용자의 영화 평점을 예측하는 모델 A 와 B 의 RMSE를 비교하는 상황을 가정해보겠습니다.\n    Model A Model B y_actual     Movie 1 3.5 4 5   Movie 2 3.5 1 3   Movie 3 3.5 5 4.5   Movie 4 3.5 2 4   Movie 5 3.5 3 2   RMSE 1.2 2.05     위 표를 보면 RMSE 값이 더 낮은 Model A 의 성능이 더 좋은 것을 확인할 수 있습니다. 하지만 실제로 Model A 가 더 좋은 추천을 해주었다고 이야기할 수 있을까요? 어떤 영화든 3.5점으로 예측하는 Model A 에 비해서 Movie 1을 4점으로 예측해 실제 5점을 받은 Model B 가 \u0026ldquo;높은 점수로 추천된 영화 중 괜찮은 영화가 있었다.\u0026ldquo;는 피드백을 받을수도 있을 것입니다.\n따라서 이러한 극단적인 경우를 포함해서 RMSE는 추천 시스템의 절대적인 좋고 나쁨의 기준이 아닌 어느 정도 성능이 나오는지에 대한 객관적인 평가로 사용하는 것이 적합하다고 할 수 있습니다.\n References  https://youtu.be/m4SNL-ZUTaA https://towardsdatascience.com/evaluate-your-recommendation-engine-using-ndcg-759a851452d1 https://github.com/jaewonlee-728/fastcampus-RecSys  ","permalink":"https://koolganni.github.io/posts/rec-sys/evaluation-metric/","summary":"추천 시스템의 성능은 어떻게 평가할까요? 어떤 추천 시스템인지에 따라 방법은 다양할 것입니다. 이번 글에서는 대표적인 정량적 평가 지표 MAP, NDCG, RMSE 에 대해 알아보겠습니다.\n 좋은 추천 시스템이란 추천 시스템의 성능, 다시 말해 사용자에게 얼마나 적절한 아이템을 추천했는지를 우리는 어떻게 평가할 수 있을까요? 서비스 관점에서는 추천 시스템을 적용하기 전과 후의 제품 매출이나 구독 등 실제 수익이 얼마나 향상되었는지를 확인해 볼 수 있을 것입니다. 혹은 A/B Test 와 같은 대조실험을 통해 어떤 추천 방법이 더 나은 고객 반응을 이끌었는지 비교해 볼 수 있을 것입니다.","title":"[추천 시스템] 추천 시스템의 성능 평가"},{"content":" 가설 검정을 하다보면 95%의 신뢰구간, 99%의 신뢰구간을 이야기할 때가 많습니다. 여기서 신뢰구간이란 정확히 무엇을 의미하는 것일까요?\n 신뢰구간과 신뢰도의 의미 먼저, 표본의 정보를 활용해 모집단의 특징을 추측하는 것을 우리는 \u0026lsquo;추정\u0026rsquo;이라고 합니다.\n모집단의 특징 중에서 모집단의 평균, 즉 모평균(μ)을 추정하는 상황을 가정해봅시다.\n예를 들어 모집단의 평균 나이가 30일 때 모평균이 1 ≤ μ ≤ 100 추정범위 안에 들어가는지 추측하는 것은 100% 확실한 추정입니다. 하지만 모평균으로 추정될 수 있는 값이 매우 많기 때문에 추정의 가치가 없다고 할 수 있습니다.\n반대로 모평균을 28 ≤ μ ≤ 32 와 같이 범위를 줄여서 추정한다면 오차가 생길 가능성이 높아지지만 추정될 수 있는 값이 몇 개 없으므로 추정으로서의 가치가 높습니다.\n이처럼 유용한 추정범위를 우리는 신뢰구간(Confidence Interval)이라 하고, 그 추정범위를 어느 정도 믿을 수 있는지에 대한 정도를 신뢰도(Confidence Level)라고 합니다.\n 신뢰구간을 구하는 방법 신뢰도는 꼭 정해진 것은 아니지만 보통 95%, 99% 를 많이 사용합니다. 95%의 신뢰도는 5%의 유의수준(⍺)을 의미하고 99%의 신뢰도는 1%의 유의수준(⍺)을 의미합니다.\n평균이 0, 표준편차가 1인 표준정규분포표를 활용하면 95% 신뢰도의 신뢰구간에 대해 다음과 같은 식을 도출할 수 있습니다.\n P(0 ≤ Z ≤ 1.96) = 0.475   P(-1.96 ≤ Z ≤ 1.96) = 0.95  여기서 Z 를 다음과 같이 풀어서 쓸 수 있습니다.\n최종적으로 유도된 식은 크기가 n 인 표본의 평균이 x̄ 일 때, 모평균 μ 에 대한 신뢰도 95%의 신뢰구간을 의미합니다.\n즉, 해당 추정범위 안에 모평균 μ 가 존재할 것으로 추정하는 것입니다.\n이때 σ 는 모집단의 표준편차를 의미하는데, 사실적으로 모집단의 평균과 분산을 알기 어렵기 때문에 추정 과정에서는 모표준편차 σ 대신 표본의 표준편차 S 를 이용합니다.\n 신뢰도, 표본의 개수, 표본표준편차에 따른 신뢰구간의 변화 1. 95%, 99% 신뢰도의 신뢰구간이 모두 표본의 개수(n)가 같은 경우  99% 신뢰도의 신뢰구간의 길이가 더 깁니다. 모평균이 99% 신뢰도의 신뢰구간에 포함될 확률이 커집니다. 오차가 생길 가능성이 낮지만 추정의 가치 또한 낮습니다.  2. 95% 신뢰도의 같은 신뢰구간에서 표본의 개수(n \u0026lt; m)가 다를 경우  개수가 m 인 표본의 신뢰구간의 길이가 더 짧습니다. 표본의 개수가 커질수록 신뢰구간의 길이가 짧아집니다. 오차가 생길 가능성이 있지만 추정의 가치가 높습니다.  3. 95% 신뢰도의 같은 신뢰구간에서 표본의 표준편차(S1 \u0026lt; S2)가 다를 경우  표준편차가 S2 인 표본의 신뢰구간의 길이가 더 깁니다. 표본의 분산이 커질수록 신뢰구간의 길이가 길어집니다. 오차가 생길 가능성이 낮지만 추정의 가치 또한 낮습니다.   그럼 모평균의 신뢰도 95%의 신뢰구간이란? 모평균을 추정할 때 우리는 여러 표본들을 사용합니다. 이때 표본들은 서로 다른 평균, 표준편차를 갖고 있습니다.\n다시 말해 각 표본마다 신뢰구간의 위치와 길이가 모두 다릅니다.\n따라서 모평균 μ 의 신뢰도 95%의 신뢰구간의 의미는 다음과 같습니다.\n 크기가 n 인 표본을 계속 (임의로) 추출해서 신뢰구간을 구하는 일을 반복한다면, 그 신뢰구간의 95% 정도가 모평균 μ 를 포함합니다.\n 정리하면 95%의 신뢰도 기준으로 100개의 표본 중 95개의 표본의 신뢰구간에 포함된 μ 가 모평균이 될 것이라 추정하는 것입니다.\n 🤖 추천 시스템에서 신뢰구간을 활용한 예시 https://tv.kakao.com/v/413991950 (27:00~)\n References  https://youtu.be/1WSTBVFeQ-4 https://nulib.github.io/moderndive_book/10-CIs.html https://saylordotorg.github.io/text_introductory-statistics/s11-01-large-sample-estimation-of-a-p.html  ","permalink":"https://koolganni.github.io/posts/statistics/confidence-interval/","summary":"가설 검정을 하다보면 95%의 신뢰구간, 99%의 신뢰구간을 이야기할 때가 많습니다. 여기서 신뢰구간이란 정확히 무엇을 의미하는 것일까요?\n 신뢰구간과 신뢰도의 의미 먼저, 표본의 정보를 활용해 모집단의 특징을 추측하는 것을 우리는 \u0026lsquo;추정\u0026rsquo;이라고 합니다.\n모집단의 특징 중에서 모집단의 평균, 즉 모평균(μ)을 추정하는 상황을 가정해봅시다.\n예를 들어 모집단의 평균 나이가 30일 때 모평균이 1 ≤ μ ≤ 100 추정범위 안에 들어가는지 추측하는 것은 100% 확실한 추정입니다. 하지만 모평균으로 추정될 수 있는 값이 매우 많기 때문에 추정의 가치가 없다고 할 수 있습니다.","title":"신뢰구간 (Confidence Interval)"},{"content":" 머신러닝 그리고 딥러닝 모델 학습에서 가장 중요한 것은 실제 값과 예측 값의 차이를 최소화해 더 정확한 예측을 하는 것입니다. 경사 하강법은 이를 위한 방법으로 \u0026lsquo;데이터를 기반으로 알고리즘이 스스로 학습한다\u0026rsquo;는 머신러닝의 개념을 실현한 핵심 기법 중 하나입니다.\n 비용 함수 (Cost Function) 아래 그림과 같이 주어진 X 에 대해 Y 를 예측하는 예측 함수, 다시 말해 가설 함수 Y = B0 + B1*X를 구하는 상황을 생각해봅시다. 우리는 실제 관측치인 주황색 점과 가설 함수의 예측치 간의 차이(error)를 최소화하는 B0(절편)과 B1(기울기)를 알아야 합니다. 이때 비용 함수(Cost Function)라는 지표를 활용합니다.\n비용 함수는 임의의 함수를 사용할 수도 있지만 일반적으로는 평균 제곱 오차(MSE)와 교차 엔트로피 오차(CEE)를 사용합니다. 이번 글에서는 평균 제곱 오차를 기준으로 살펴보겠습니다.\n위에서 살펴본 B 값을 앞으로는 θ 값으로 바꿔 이야기해보겠습니다. 가설 함수 h(x) 의 값은 정해진 변수 𝑥 값 외에 미지의 θ 값에 의해 결정됩니다.\n우리의 목적은 비용 함수, 즉 실제 값과 예측 값의 차이를 최소화(minimize) 하는 θ 값을 찾는 것입니다. 이때 경사 하강법(Gradient Descent)을 사용합니다.\n 경사 하강법 (Gradient Descent) 위에서 살펴본 비용 함수를 그래프로 나타내면 아래와 같이 포물선 형태의 2차 함수를 확인할 수 있습니다. 그리고 θ 값 다시 말해 Weight 값에 따라 비용 함수의 값이 달라지는 것을 볼 수 있습니다.\n비용 함수의 값이 최소인 부분이자 실제 값과 예측 값의 차이가 최소인 부분으로 다가갈수록 2차 함수인 비용 함수를 미분한 값, 즉 1차 함수의 기울기(Gradient) 가 0에 가까워짐을 알 수 있습니다.\n경사 하강법은 이처럼 초기 Weight 에서부터 미분을 적용해 이 미분한 값, 즉 기울기가 계속 감소하는 방향으로 Weight 를 업데이트합니다. 그리고 이 기울기가 더 이상 감소하지 않는 지점을 우리가 찾고자 하는 비용 함수가 최소인 지점으로 간주합니다.\n경사 하강법의 계산 과정을 수식으로 간단히 살펴보겠습니다.   Update rules : ɑ 와 \u0026lsquo;비용 함수를 θ 로 미분한 값\u0026rsquo;을 곱한 값으로 θ 값을 업데이트합니다.\n ɑ : 학습률(Learning rate) 값을 의미하며 θ 값을 얼마나 업데이트할지 결정합니다. ɑ 가 너무 크면 θ 값이 큰 값으로 발산해버릴 수 있고 반대로 너무 작다면 최적의 θ 값을 찾을 때까지 시간이 너무 오래 걸리거나 찾지 못할 수 있습니다.    Derivatives : 비용 함수를 θ 로 미분한 결과입니다.\n 연쇄 법칙(Chain Rule)을 활용하면 쉽게 계산할 수 있습니다.     Local Minimum 과 Global Minimum 경사 하강법은 기울기를 기준으로 비용 함수가 최소가 되는 지점을 찾는다고 이야기 했습니다. 하지만 해당 지점이 항상 최솟값이라는 보장을 할 수 있을까요?\n위에서 살펴본 선형 회귀를 위한 MSE 비용 함수의 경우 볼록 함수(Convex Function)로 초기 Weight 가 어디에서 시작하는지 상관없이 단 하나의 최솟값을 찾게 됩니다.\n하지만 주어진 𝑥 다시 말해 Feature 의 개수가 늘어난다면 비용 함수는 아래와 같이 비볼록 함수(Non-convex Function)가 될 것입니다.\n비볼록 함수는 시작 위치에 따라 다른 지점을 찾기 때문에 전역 최솟값(Global Minimum)을 찾지 못하고 지역 최솟값(Local Minimum)에 빠질 위험이 있습니다. 사실 우리가 마주칠 대부분의 문제는 이러한 비볼록 함수이므로 단순한 경사 하강법으로는 한계가 있습니다.\n이를 해결하기 위한 방법 중 하나로 기울기에 관성을 부과한 모멘텀(Momentum)이라는 방법이 있습니다. 자세한 내용은 다음 글에서 알아보겠습니다.\n References  https://youtu.be/TxIVr-nk1so https://www.boostcourse.org/ai222/lecture/24509 밑바닥부터 시작하는 딥러닝 1 - 한빛미디어 (2017)  ","permalink":"https://koolganni.github.io/posts/machine-learning/gradient-descent/","summary":"머신러닝 그리고 딥러닝 모델 학습에서 가장 중요한 것은 실제 값과 예측 값의 차이를 최소화해 더 정확한 예측을 하는 것입니다. 경사 하강법은 이를 위한 방법으로 \u0026lsquo;데이터를 기반으로 알고리즘이 스스로 학습한다\u0026rsquo;는 머신러닝의 개념을 실현한 핵심 기법 중 하나입니다.\n 비용 함수 (Cost Function) 아래 그림과 같이 주어진 X 에 대해 Y 를 예측하는 예측 함수, 다시 말해 가설 함수 Y = B0 + B1*X를 구하는 상황을 생각해봅시다. 우리는 실제 관측치인 주황색 점과 가설 함수의 예측치 간의 차이(error)를 최소화하는 B0(절편)과 B1(기울기)를 알아야 합니다.","title":"경사 하강법 (Gradient Descent)"}]